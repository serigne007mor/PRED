Return-Path: <p_bruneau@hotmail.com>
X-Original-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Received: from bouncesmtp2.univ-nantes.fr (bouncesmtp2.u12.univ-nantes.prive [172.20.12.67])
	by sympa62.u12.univ-nantes.prive (Postfix) with ESMTP id 75AB414017C0
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Wed, 15 Feb 2023 07:01:49 +0100 (CET)
Received: from mx3.localdomain (MX3.univ-nantes.fr [193.52.101.137])
	by bouncesmtp2.univ-nantes.fr (Postfix) with ESMTP id 6DF64926
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Wed, 15 Feb 2023 07:01:49 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
	by mx3.localdomain (Postfix) with ESMTP id 60EE220DFA
	for <liste-egc@polytech.univ-nantes.fr>; Wed, 15 Feb 2023 07:01:49 +0100 (CET)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: YES
X-Spam-Score: 10.012
X-Spam-Level: **********
X-Spam-Status: Yes, score=10.012 tagged_above=-1000 required=5
	tests=[CRM114_UNSURE=0.1, DKIM_SIGNED=0.1, DKIM_VALID=-0.1,
	DKIM_VALID_AU=-0.1, DKIM_VALID_EF=-0.1, FREEMAIL_FROM=0.001,
	HTML_MESSAGE=0.001, RCVD_IN_DNSWL_NONE=-0.0001, RCVD_IN_WSFF=0.01,
	SPF_HELO_NONE=0.001, SPF_PASS=-0.001, UN_CANADIAN_RX=10,
	UN_PHISHING_PW=0.1] autolearn=disabled
X-CRM114-Status: UNSURE ( 2.3233 )
X-CRM114-CacheID: 
Authentication-Results: univ-nantes.fr (amavisd-new); dkim=pass (2048-bit key)
	header.d=gmail.com
Received: from mx3.localdomain ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id F-wKYRhTkE0U for <liste-egc@polytech.univ-nantes.fr>;
	Wed, 15 Feb 2023 07:01:46 +0100 (CET)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from mail-ej1-x634.google.com (mail-ej1-x634.google.com [IPv6:2a00:1450:4864:20::634])
	by mx3.localdomain (Postfix) with ESMTPS id D8A3820CE8
	for <liste-egc@polytech.univ-nantes.fr>; Wed, 15 Feb 2023 07:01:46 +0100 (CET)
Received: by mail-ej1-x634.google.com with SMTP id a3so11509852ejb.3
        for <liste-egc@polytech.univ-nantes.fr>; Tue, 14 Feb 2023 22:01:46 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20210112;
        h=to:subject:message-id:date:from:mime-version:from:to:cc:subject
         :date:message-id:reply-to;
        bh=JO4bqnUumakjldsHpIEZ4U5KbuzwZqAHihLZvOIrG3M=;
        b=cvwOq7O2eKYut53a3yClx2hzXcnWRhdu7WHvev3SuPc/dmzj11kxNM8jf8ElH1AbEv
         mS+FStFYgP/2ARAjvSGFpwtgKLkOoQ9E09pyKEEFnejASJDIJe3O1JIXLX9fBYlZvvJh
         +b6kpHlEu8kwiLYG+xJWHMMqv1t+3hrkirugjDQDINPLekNhEJLvB5H4k/hgJMEnJtSP
         804dUnjHatqJpDRXvNJ9aLlxHkV17nYT0DsYcLcSLh5porJqz61Q/8FrxOkXy11IcEiE
         49gRbNlw1vtjpTvSslE+PZWJf+VKh6sIggI6lATzc+gUuvZ71AeRG4pjsfDExxNVhVVI
         5iKw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20210112;
        h=to:subject:message-id:date:from:mime-version:x-gm-message-state
         :from:to:cc:subject:date:message-id:reply-to;
        bh=JO4bqnUumakjldsHpIEZ4U5KbuzwZqAHihLZvOIrG3M=;
        b=lISqQFPR9iGeLhNrfOg4eBq9L9PBqXmJvPqE54GF1fgnAR7FOtMRPJEycVa5c51/p/
         N8aeWzcU7DDjiHGBWq9STBPihqB1o/eChHVQfw3R9hM4ll22LmViUBmS7cn9jr+zOEkg
         6RrCx3W9y2ala5uIQO3p+nPDnaqnv1+ZDYCN63FGc3ZI2+/RfYxlawAaDgNw8qJF45oS
         X9UH3tc7DKXGbGYUpZ6waLyrJHvIhQ2CIKcPDQ7G7rjgO0hiN43yBqSqWX144+efLLg/
         cIL6Dk1EQSUmLgsncv67AhhWGqNSAIF8n6aWdQ01kRGisXj42JlR1SQEbk+mvOmMkKGx
         t5lQ==
X-Gm-Message-State: AO0yUKXHhhYwP5awFGgX5nBtaxNTlUp1b6iUW3f+KiaMt09ZDiiI3tbc
	z2lwpeyM6VW20RIZYIAiBMnmRqXX+GAbf0MSiPinVjd7tBN1/g==
X-Google-Smtp-Source: AK7set833t9Xf25JbhZCsIB8UpIYXzAl2Cj8JI64H7brXVv64zLOeNbCMNmJz2dOwt89nWTeM5NEQ3kUE/Ta6m2fq9Y=
X-Received: by 2002:a17:906:4e84:b0:877:7480:c75d with SMTP id
 v4-20020a1709064e8400b008777480c75dmr536763eju.0.1676440905871; Tue, 14 Feb
 2023 22:01:45 -0800 (PST)
MIME-Version: 1.0
From: Hakim Hacid <hakim.hacid@gmail.com>
Date: Wed, 15 Feb 2023 10:01:34 +0400
Message-ID: <CAF72FM8AaFHPzhD+qf8E9A284e3r5LjTTjNCy15W-GdnkHJW4g@mail.gmail.com>
To: liste-egc@polytech.univ-nantes.fr
Content-Type: multipart/alternative; boundary="000000000000ae758d05f4b6d084"
X-Validation-by: p_bruneau@hotmail.com
Subject: [liste-egc] [SPAM] CFP: The First International Workshop on Small
 Precision for Machine Learning (SPINAL 2023) @ PAKDD 2023

--000000000000ae758d05f4b6d084
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

***
*** Apologies if you receive this call multiple times!
***
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
THE FIRST INTERNATIONAL WORKSHOP ON
SMALL PRECISION FOR MACHINE LEARNING (SPINAL 2023)
In Conjunction with PAKDD 2023

25-28 May, Osaka, Japan
http://spinal2023.josueonline.com/
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D

CALL FOR PAPERS:
----------------
The surge in demand and interest in more potent AI and machine learning
applications has fueled the race to build larger models, powerful
algorithms and heavy digital infrastructures to ensure production and
delivery breakthroughs in machine learning (ML) systems. At the heart of
this technological transformation, it is hard to omit the role of dedicated
processors for ML applications to accelerate the learning process and speed
up computation of machine learning models for both training and inference
workloads, and to cope with trends of the increasing complexity of ML
applications.

As model and dataset size requirements of deep learning applications
continue to increase, in order to address the growing compute, storage, and
connectivity requirements,  scalability of machine learning systems becomes
even more critical. Indeed, efficient training of large models is
synonymous with the efficient use of the available compute, power, memory,
and networking resources to overcome any physical limitations when training
such large models over a large distributed infrastructure.

Choice of computer arithmetic is an important part in any accelerator
design, as it has a direct impact on the hardware complexity and compute
efficiency, as well as the utilization of the available memory and
communication bandwidth. In addition, efficient numerical representation is
indispensable as it offers prospects of an improved power efficiency
achieved through higher compute throughput and better utilization of the
communication bandwidth.

In addition to model training and turning, several challenges arise during
deployment of large models as a result of the increased computational
complexity and tight latency requirements. To overcome these challenges,
numerical quantisation for inference is a necessity to utilize the limited
compute and memory available in small-powered devices or infrastructure
used to serve these workloads.

With the slowdown of Moore's law, and the reality that the current silicon
technology is no longer able to double the processing speed with every new
silicon generation at a constant power, the need for today=E2=80=99s and to=
morrow's
ML processors and accelerators to make more efficient use of the available
power is paramount. The demand is expected to grow and catch more interest
due to the current physical limitations of cloud, edge, and mobile
solutions. This workshop intends to gather researchers and practitioners in
the area of low precision arithmetic for machine learning and offer a
platform for an exchange of ideas, and to discuss the progress in the area
as well as to address emerging future challenges. Areas of interest
include, but are not limited to:

- Low precision training
- Low precision inference
- On-chip ring communication
- Power management
- Benchmarks and frameworks for low precision ML
- NLP optimizations
- Computer vision optimizations

SPECIAL ISSUE
--------------
The workshop organizers are exploring special issue opportunities with few
journals. More information will be available very soon.

IMPORTANT DATES
-----------------
Submission deadline: March 7, 2023
Acceptance notification: April 7, 2023
Camera-ready submission: April 25, 2023

SUBMISSION WEBSITE:
--------------------
Please submit your contributions on the following link:
https://easychair.org/conferences/?conf=3Dspinal2023

WORKSHOP ORGANIZERS:
---------------------
- Badreddine Noune, Technology Innovation Institute Abu Dhabi, UAE
- Hakim Hacid, Technology Innovation Institute, Abu Dhabi, UAE
- Imran Junejo, AMD, Canada

--000000000000ae758d05f4b6d084
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>***</div><div>*** Apologies if you receive this call =
multiple times!=C2=A0</div><div>***</div>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D<br>THE FIRST INTERNATIONAL WORKSHOP ON <br>SMALL PRECISION FOR MACHI=
NE LEARNING (SPINAL 2023)<br>In Conjunction with PAKDD 2023<br><br>25-28 Ma=
y, Osaka, Japan<br><a href=3D"http://spinal2023.josueonline.com/">http://sp=
inal2023.josueonline.com/</a><br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br=
><br>CALL FOR PAPERS:<br>----------------<br>The surge in demand and intere=
st in more potent AI and machine learning applications has fueled the race =
to build larger models, powerful algorithms and heavy digital infrastructur=
es to ensure production and delivery breakthroughs in machine learning (ML)=
 systems. At the heart of this technological transformation, it is hard to =
omit the role of dedicated processors for ML applications to accelerate the=
 learning process and speed up computation of machine learning models for b=
oth training and inference workloads, and to cope with trends of the increa=
sing complexity of ML applications.<br><br>As model and dataset size requir=
ements of deep learning applications continue to increase, in order to addr=
ess the growing compute, storage, and connectivity requirements, =C2=A0scal=
ability of machine learning systems becomes even more critical. Indeed, eff=
icient training of large models is synonymous with the efficient use of the=
 available compute, power, memory, and networking resources to overcome any=
 physical limitations when training such large models over a large distribu=
ted infrastructure.<br><br>Choice of computer arithmetic is an important pa=
rt in any accelerator design, as it has a direct impact on the hardware com=
plexity and compute efficiency, as well as the utilization of the available=
 memory and communication bandwidth. In addition, efficient numerical repre=
sentation is indispensable as it offers prospects of an improved power effi=
ciency achieved through higher compute throughput and better utilization of=
 the communication bandwidth.<br><br>In addition to model training and turn=
ing, several challenges arise during deployment of large models as a result=
 of the increased computational complexity and tight latency requirements. =
To overcome these challenges, numerical quantisation for inference is a nec=
essity to utilize the limited compute and memory available in small-powered=
 devices or infrastructure used to serve these workloads.<br><br>With the s=
lowdown of Moore&#39;s law, and the reality that the current silicon techno=
logy is no longer able to double the processing speed with every new silico=
n generation at a constant power, the need for today=E2=80=99s and tomorrow=
&#39;s ML processors and accelerators to make more efficient use of the ava=
ilable power is paramount. The demand is expected to grow and catch more in=
terest due to the current physical limitations of cloud, edge, and mobile s=
olutions. This workshop intends to gather researchers and practitioners in =
the area of low precision arithmetic for machine learning and offer a platf=
orm for an exchange of ideas, and to discuss the progress in the area as we=
ll as to address emerging future challenges. Areas of interest include, but=
 are not limited to:<br><br>- Low precision training<br>- Low precision inf=
erence<br>- On-chip ring communication<br>- Power management<br>- Benchmark=
s and frameworks for low precision ML<br>- NLP optimizations<br>- Computer =
vision optimizations<br><br>SPECIAL ISSUE<br>--------------<br>The workshop=
 organizers are exploring special issue opportunities with few journals. Mo=
re information will be available very soon. <br><br>IMPORTANT DATES<br>----=
-------------<br>Submission deadline: March 7, 2023<br>Acceptance notificat=
ion: April 7, 2023<br>Camera-ready submission: April 25, 2023<br><br>SUBMIS=
SION WEBSITE:<br>--------------------<br>Please submit your contributions o=
n the following link: <a href=3D"https://easychair.org/conferences/?conf=3D=
spinal2023">https://easychair.org/conferences/?conf=3Dspinal2023</a><span c=
lass=3D"gmail-Apple-converted-space">=C2=A0</span><div><br><div>WORKSHOP OR=
GANIZERS: <br>---------------------<br>- Badreddine Noune, Technology Innov=
ation Institute Abu Dhabi, UAE<br>- Hakim Hacid, Technology Innovation Inst=
itute, Abu Dhabi, UAE<br>- Imran Junejo, AMD, Canada<br><br><br><br></div><=
/div></div>

--000000000000ae758d05f4b6d084--
