Return-Path: <sadok.benyahia@fst.rnu.tn>
X-Original-To: polytech_liste-egc@sympa6.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa6.univ-nantes.prive
Received: from bouncesmtp2.univ-nantes.fr (BounceSMTP2.univ-nantes.prive [172.20.12.67])
	by sympa6.univ-nantes.prive (Postfix) with ESMTP id E3F7A1813EFC
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Sun, 17 Aug 2014 01:23:51 +0200 (CEST)
Received: from mx2.d101.univ-nantes.fr (MX2.univ-nantes.fr [193.52.101.136])
	by bouncesmtp2.univ-nantes.fr (Postfix) with ESMTP id DB5A5676D28
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Sun, 17 Aug 2014 01:23:51 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mx2.d101.univ-nantes.fr (Postfix) with ESMTP id CFA9D32E10
	for <liste-egc@polytech.univ-nantes.fr>; Sun, 17 Aug 2014 01:23:51 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: -2.815
X-Spam-Level:
X-Spam-Status: No, score=-2.815 tagged_above=-1000 required=5
	tests=[CRM114_GOOD=-5, HTML_MESSAGE=0.001, MR_NOT_ATTRIBUTED_IP=0.2,
	NO_RDNS=0.5, RCVD_IN_DNSWL_NONE=-0.0001, RCVD_IN_WSFF=0.01,
	RDNS_NONE=1.274, UN_PHISHING_COMPTE=0.1, UN_PHISHING_PW=0.1]
	autolearn=disabled
X-CRM114-Status: GOOD ( 7.6807 )
X-CRM114-CacheID: 
Received: from mx2.d101.univ-nantes.fr ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id 5j3D0oOxuwYI for <liste-egc@polytech.univ-nantes.fr>;
	Sun, 17 Aug 2014 01:23:49 +0200 (CEST)
X-Greylist: from auto-whitelisted by SQLgrey-1.6.7
Received: from cckmail20.outgw.tn (unknown [196.203.250.158])
	by mx2.d101.univ-nantes.fr (Postfix) with ESMTP id CA34B6297FE5
	for <liste-egc@polytech.univ-nantes.fr>; Sun, 17 Aug 2014 01:23:48 +0200 (CEST)
Received: from smtp.rnrt.tn (unknown [196.203.79.188])
	by cckmail20.outgw.tn (Postfix) with ESMTP id 3ACA131D0003;
	Sun, 17 Aug 2014 01:23:47 +0200 (CEST)
Received: from smtp (smtp.rnu.tn [196.203.79.243])
	by smtp.rnrt.tn (Postfix) with ESMTP id 2DF89F78A71;
	Sat, 16 Aug 2014 23:57:01 +0100 (CET)
Received: from [192.168.1.103] (unknown [197.31.230.200])
	by smtp (Postfix) with ESMTPA id B90D1100C75;
	Sun, 17 Aug 2014 01:16:20 +0200 (CEST)
Message-ID: <53EFE6FF.8070105@fst.rnu.tn>
Date: Sun, 17 Aug 2014 00:19:27 +0100
From: Sadok Ben Yahia <sadok.benyahia@fst.rnu.tn>
User-Agent: Mozilla/5.0 (X11; Linux i686; rv:24.0) Gecko/20100101 Thunderbird/24.4.0
MIME-Version: 1.0
To: liste-egc@polytech.univ-nantes.fr, bull-i3@irit.fr
References: <53215DDF.6010501@fst.rnu.tn>
In-Reply-To: <53215DDF.6010501@fst.rnu.tn>
Content-Type: multipart/alternative;
 boundary="------------030003010209030607000100"
X-Validation-by: cyril.de-runz@univ-reims.fr
Subject: [liste-egc] =?WINDOWS-1252?Q?Re=3A_Soutenance_de_th=E8se_de_Mr_Fa?=
 =?WINDOWS-1252?Q?thi_FERJANI=3A_Conceptual_Feature_Extraction_from_Texts?=
 =?WINDOWS-1252?Q?=3A_Document_Structuring_and_Categorization?=

This is a multi-part message in MIME format.
--------------030003010209030607000100
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit

Bonjour,

J'ai le plaisir et l'honneur de vous inviter à la soutenance publique de 
ma thèse de Doctorat en Informatique, intitulée: "Conceptual Feature 
Extraction from Texts: Document Structuring and Categorization"
qui aura lieu le *jeudi  21 Aout 2014 à 12h* dans la salle des 
conférences du Département des Sciences de l'Informatique.

Bien Cordialement,
Fathi Ferjani

Le jury de soutenance sera composé de:

Mr. Khaled BSAIES Professeur, FST,  Tunis: Président
Mr. Mathieu ROCHE Directeur de recherches, CEMAGREF, France: Rapporteur
Mr. Mohamed Mohsen GAMMOUDI Professeur, ISAMM, Tunis: Rapporteur
Mr. Nejib HADJ ALOUANE Professeur, ENIT, Tunis: Examinateur
Mr. Sadok Ben Yahia Professeur, FST, Tunis: Directeur de thèse
Mr. Ali JAOUA, Professeur, Qatar University, co-directeur
Mr. Samir ELLUOMI, Maitre-assistant, co-encadrant

Titre: Conceptual Feature Extraction from Texts: Document Structuring 
and Categorization

Mots clés : Analyse de concepts formels, couverture conceptuelle, 
réduction de la dimensionnalité, étiquette isolée, étiquette composée 
isolée, hyper-concept
Résumé:


Text Mining ou fouille de textes (TM) permet de découvrir  des 
informations "importantes" à partir d'un corpus constitué de données 
textuelles. Ces informations peuvent être utilisées pour la 
catégorisation automatique des documents selon les thèmes, la détection 
des avis dans le cadre du web social, la sécurité et la lutte contre le 
terrorisme, etc.
La qualité des informations découvertes par les techniques du TM est un 
élément primordial pour un usage efficace et diversifié. En effet, TM 
fait face à plusieurs défis notamment (i) la complexité et l'ambiguïté 
du Traitement du Langage Naturel (TLN); et (ii) le volume colossal de 
données textuelles qui ne cesse de s'accroître tous les jours, etc.
  Dans le cadre de cette thèse, nous proposons une phase de 
pré-traitement qui tient compte de l'aspect sémantique du texte et la 
corrélation entre les mots afin d'en réduire l'ambiguïté 
d'interprétation selon leur contexte au sein du document. Pour faire 
face au problème de l'accroissement continu du volume de données, nous 
avons recours à la réduction de la dimensionnalité (DR) connue sous le 
nom de "malédiction de la dimension". DR est le processus de 
transformation d'un volume important de données textuelles dans une 
représentation minimale, moins bruyante qui aide à déterminer quels mots 
dans un document décrivent le mieux son contenu.
Fondamentalement, nous avons quatre principales contributions. Dans la 
première contribution, nous incluons les aspects sémantiques des 
documents textuels nécessitant une phase de pré-traitement afin 
d'obtenir une représentation sémantique de documents textuels 
non-structurés. Nous avons essentiellement mis l'accent sur les 
techniques entièrement non-structurées. L'objectif est de relier les 
termes spécifiques à un domaine donné en utilisant l'ontologie Word-Net  
(i.e., pour résoudre les problèmes de synonymes et hyponymes) et "part 
of speech tagging" (POS) pour déterminer les aspects grammaticaux des 
mots impliqués dans un corpus donné. Cela implique la spécification du 
groupe de mots qui sont adjacents et intimement liés.
Après la phase de raffinement des documents textuels, ces données 
peuvent être mappées dans un espace de dimension réduite. De cela, nous 
proposons une nouvelle heuristique pour identifier un sous-ensemble de 
concepts où chacun contient des mots simples, ou des mots composés 
(i.e., également appelé propriétés composées), appartenant à une seule 
notion. Cette contribution se concentre sur la réduction de la 
dimensionnalité des données et générer des étiquettes efficaces qui 
couvrent les données textuelles traitées. Malheureusement, la grande 
complexité des concepts extraits est encore élevée. Donc, étant donné 
qu'il existe une corrélation entre les points isolés et les générateurs 
minimaux, nous proposons une amélioration de la précédente. Son objectif 
principal est de réduire la complexité de temps tout en préservant un 
niveau de cohésion élevé. Enfin, les principaux inconvénients des 
solutions proposées sont affectés par l'absence de liaisons sémantiques 
entre les concepts extraits. Pour cette raison, nous proposons notre 
dernière approche qui se prête avec des termes interdépendants dans un 
document textuel donné. Dans cette thèse, nous proposons une "approche 
Hyper-conceptuelle", qui définit les liens entre les termes dans une 
structure hiérarchique dans l'ordre décroissant de leur importance. Pour 
conclure, nous présentons les principales difficultés rencontrées, les 
solutions proposées pour remédier à ces lacunes et nous décrivons les 
orientations des récentes recherches dans ce domaine.


--------------030003010209030607000100
Content-Type: text/html; charset=windows-1252
Content-Transfer-Encoding: 8bit

<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    Bonjour,<br>
    <br>
    J'ai le plaisir et l'honneur de vous inviter à la soutenance
    publique de ma thèse de Doctorat en Informatique, intitulée:
    "Conceptual Feature Extraction from Texts: Document Structuring and
    Categorization" <br>
    qui aura lieu le <b>jeudi  21 Aout 2014 à 12h</b> dans la salle des
    conférences du Département des Sciences de l'Informatique. <br>
    <br>
    Bien Cordialement,<br>
    Fathi Ferjani<br>
    <br>
    Le jury de soutenance sera composé de:<br>
    <br>
    Mr. Khaled BSAIES Professeur, FST,  Tunis: Président<br>
    Mr. Mathieu ROCHE Directeur de recherches, CEMAGREF, France:
    Rapporteur<br>
    Mr. Mohamed Mohsen GAMMOUDI Professeur, ISAMM, Tunis: Rapporteur<br>
    Mr. Nejib HADJ ALOUANE Professeur, ENIT, Tunis: Examinateur<br>
    Mr. Sadok Ben Yahia Professeur, FST, Tunis: Directeur de thèse<br>
    Mr. Ali JAOUA, Professeur, Qatar University, co-directeur<br>
    Mr. Samir ELLUOMI, Maitre-assistant, co-encadrant<br>
    <br>
    Titre: Conceptual Feature Extraction from Texts: Document
    Structuring and Categorization<br>
    <br>
    Mots clés : Analyse de concepts formels, couverture conceptuelle,
    réduction de la dimensionnalité, étiquette isolée, étiquette
    composée isolée, hyper-concept<br>
    Résumé:<br>
    <br>
    <br>
    Text Mining ou fouille de textes (TM) permet de découvrir  des
    informations "importantes" à partir d'un corpus constitué de données
    textuelles. Ces informations peuvent être utilisées pour la
    catégorisation automatique des documents selon les thèmes, la
    détection des avis dans le cadre du web social, la sécurité et la
    lutte contre le terrorisme, etc.<br>
    La qualité des informations découvertes par les techniques du TM est
    un élément primordial pour un usage efficace et diversifié. En
    effet, TM fait face à plusieurs défis notamment (i) la complexité et
    l'ambiguïté du Traitement du Langage Naturel (TLN); et (ii) le
    volume colossal de données textuelles qui ne cesse de s'accroître
    tous les jours, etc.<br>
     Dans le cadre de cette thèse, nous proposons une phase de
    pré-traitement qui tient compte de l'aspect sémantique du texte et
    la corrélation entre les mots afin d'en réduire l'ambiguïté
    d'interprétation selon leur contexte au sein du document. Pour faire
    face au problème de l'accroissement continu du volume de données,
    nous avons recours à la réduction de la dimensionnalité (DR) connue
    sous le nom de "malédiction de la dimension". DR est le processus de
    transformation d'un volume important de données textuelles dans une
    représentation minimale, moins bruyante qui aide à déterminer quels
    mots dans un document décrivent le mieux son contenu.<br>
    Fondamentalement, nous avons quatre principales contributions. Dans
    la première contribution, nous incluons les aspects sémantiques des
    documents textuels nécessitant une phase de pré-traitement afin
    d'obtenir une représentation sémantique de documents textuels
    non-structurés. Nous avons essentiellement mis l'accent sur les
    techniques entièrement non-structurées. L'objectif est de relier les
    termes spécifiques à un domaine donné en utilisant l'ontologie
    Word-Net  (i.e., pour résoudre les problèmes de synonymes et
    hyponymes) et "part of speech tagging" (POS) pour déterminer les
    aspects grammaticaux des mots impliqués dans un corpus donné. Cela
    implique la spécification du groupe de mots qui sont adjacents et
    intimement liés.<br>
    Après la phase de raffinement des documents textuels, ces données
    peuvent être mappées dans un espace de dimension réduite. De cela,
    nous proposons une nouvelle heuristique pour identifier un
    sous-ensemble de concepts où chacun contient des mots simples, ou
    des mots composés (i.e., également appelé propriétés composées),
    appartenant à une seule notion. Cette contribution se concentre sur
    la réduction de la dimensionnalité des données et générer des
    étiquettes efficaces qui couvrent les données textuelles traitées.
    Malheureusement, la grande complexité des concepts extraits est
    encore élevée. Donc, étant donné qu'il existe une corrélation entre
    les points isolés et les générateurs minimaux, nous proposons une
    amélioration de la précédente. Son objectif principal est de réduire
    la complexité de temps tout en préservant un niveau de cohésion
    élevé. Enfin, les principaux inconvénients des solutions proposées
    sont affectés par l'absence de liaisons sémantiques entre les
    concepts extraits. Pour cette raison, nous proposons notre dernière
    approche qui se prête avec des termes interdépendants dans un
    document textuel donné. Dans cette thèse, nous proposons une
    "approche Hyper-conceptuelle", qui définit les liens entre les
    termes dans une structure hiérarchique dans l'ordre décroissant de
    leur importance. Pour conclure, nous présentons les principales
    difficultés rencontrées, les solutions proposées pour remédier à ces
    lacunes et nous décrivons les orientations des récentes recherches
    dans ce domaine.<br>
    <br>
  </body>
</html>

--------------030003010209030607000100--
