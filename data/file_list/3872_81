Return-Path: <p_bruneau@hotmail.com>
X-Original-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Received: from BounceSmtp1.univ-nantes.fr (bouncesmtp1.u12.univ-nantes.prive [172.20.12.66])
	by sympa62.u12.univ-nantes.prive (Postfix) with ESMTP id 1AAD214017D6
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Thu, 27 Apr 2023 17:09:46 +0200 (CEST)
Received: from mx1.localdomain (MX1.univ-nantes.fr [193.52.101.135])
	by BounceSmtp1.univ-nantes.fr (Postfix) with ESMTP id 16D3C7065
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Thu, 27 Apr 2023 17:09:46 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mx1.localdomain (Postfix) with ESMTP id 0B3CC12045D
	for <liste-egc@polytech.univ-nantes.fr>; Thu, 27 Apr 2023 17:09:46 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: -3.387
X-Spam-Level:
X-Spam-Status: No, score=-3.387 tagged_above=-1000 required=5
	tests=[CRM114_GOOD=-5, DKIM_SIGNED=0.1, DKIM_VALID=-0.1,
	DKIM_VALID_AU=-0.1, DKIM_VALID_EF=-0.1, FREEMAIL_FROM=0.001,
	HTML_FONT_LOW_CONTRAST=0.001, HTML_MESSAGE=0.001,
	HTTPS_HTTP_MISMATCH=0.1, HTTP_ESCAPED_HOST=0.1,
	MR_STRANGE_QUESTION=1.5, RCVD_IN_DNSWL_NONE=-0.0001,
	RCVD_IN_WSFF=0.01, SPF_HELO_NONE=0.001, SPF_PASS=-0.001,
	UN_PHISHING_PW=0.1] autolearn=disabled
X-CRM114-Status: GOOD ( 6.0109 )
X-CRM114-CacheID: 
Authentication-Results: univ-nantes.fr (amavisd-new); dkim=pass (2048-bit key)
	header.d=gmail.com
Received: from mx1.localdomain ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id JUUo7wXkoz1I for <liste-egc@polytech.univ-nantes.fr>;
	Thu, 27 Apr 2023 17:09:43 +0200 (CEST)
Received-SPF: Pass (mailfrom) identity=mailfrom; client-ip=2607:f8b0:4864:20::535; helo=mail-pg1-x535.google.com; envelope-from=boutalbi.rafika@gmail.com; receiver=liste-egc@polytech.univ-nantes.fr 
Authentication-Results: dmarc.univ-nantes.fr; dmarc=pass (p=none dis=none) header.from=gmail.com
Authentication-Results: dmarc.univ-nantes.fr; spf=pass smtp.mailfrom=boutalbi.rafika@gmail.com
Authentication-Results: dkim.univ-nantes.fr;
	dkim=pass (2048-bit key; unprotected) header.d=gmail.com header.i=@gmail.com header.b="Me++DN68";
	dkim-atps=neutral
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from mail-pg1-x535.google.com (mail-pg1-x535.google.com [IPv6:2607:f8b0:4864:20::535])
	by mx1.localdomain (Postfix) with ESMTPS id 0A91C120047
	for <liste-egc@polytech.univ-nantes.fr>; Thu, 27 Apr 2023 17:09:43 +0200 (CEST)
Received: by mail-pg1-x535.google.com with SMTP id 41be03b00d2f7-51b661097bfso6601074a12.0
        for <liste-egc@polytech.univ-nantes.fr>; Thu, 27 Apr 2023 08:09:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20221208; t=1682608181; x=1685200181;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :from:to:cc:subject:date:message-id:reply-to;
        bh=AYaAi54Ypu1dYIoVERCoJ8GV3y0pOZNE//+dOnftg4M=;
        b=Me++DN68IBX4YkKHEOTf3vKtUm77ERFvY6vaG2Y4cLxhGsGeD3r8foAUa8J4nm3wlB
         PXRKjhqj2uYaSQQklUzoglvVIpMrvrxY5vpmu64ItEKLDLFaaRO2Y5zAomLiwKP6dPiC
         lko0mTVSsPJIx2uSwJB8rH7QT4NqdchzWo9D8j2zTGewjyuwKibRPxKcy5pdCzI5V5mC
         lgC27lz4qpcnhwUt8N6rdOb05tP01XuMHWAkTHxPQ2zI27HV+E2M3qvatj22oaMY0goB
         +nyJnh/H25/lcy93Td3kzV/sQFeZnDmDlCK89sXCG81zs3GYWUlCVoKcqcwVq7A9IGim
         jchg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20221208; t=1682608181; x=1685200181;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :x-gm-message-state:from:to:cc:subject:date:message-id:reply-to;
        bh=AYaAi54Ypu1dYIoVERCoJ8GV3y0pOZNE//+dOnftg4M=;
        b=iUzLvl7qvA8ri+HH+/CQbfTls/puZNQcx5E2+wyRYAx88Dt5y7DU3KbJ9mk9wcS3ka
         NP1hyzorhkbN+DpOUfbvAVAGV8wRGndaxf1gV0X8IDuf9/PrZ5qidxQNlfLpQ0bwGv2r
         Gp/IRYRF1bCn05XJ7Ar1dZBCz1as1QpIzw/TRw/k3xC12r06eV5G6it6LarYwa3bIeJ1
         wP2mkRCo931IByQm1VY/vrnxpMOmNQRICvB8MXD3pPgaXOC/BV26vbcZj/TJxMFAEu9A
         na7KjCLk1AqgKVK4Ku4g0kqtb+bIJlTFi8nIxCiXC/gI2AjYMjv702u340e/Jp8Qabap
         w85w==
X-Gm-Message-State: AC+VfDyXjQCs+/60ayEoD7kg1LF0jT9aKUitwFgtDdZcS/8e9ZTMxIDg
	CZMTHXE4ItPfWYc4kCy7zfZydx4zKs0i0A9mPwnSbISwQ8SlZA==
X-Google-Smtp-Source: ACHHUZ5+cYrV6lIYohl1mZn65pfPlwnbxpmQuC9cBJwjBynM9rdFeTwBQI0nQxciBNv6rP+9ntiqF2dlcqWGfZk71H8=
X-Received: by 2002:a17:90b:1a86:b0:234:28ac:ec4a with SMTP id
 ng6-20020a17090b1a8600b0023428acec4amr2140132pjb.2.1682608180866; Thu, 27 Apr
 2023 08:09:40 -0700 (PDT)
MIME-Version: 1.0
References: <CANx104uQdWLqZEjbin-s=aTgm1RFBqC65SiE4DPNGz-Othrm3w@mail.gmail.com>
In-Reply-To: <CANx104uQdWLqZEjbin-s=aTgm1RFBqC65SiE4DPNGz-Othrm3w@mail.gmail.com>
From: rafika boutalbi <boutalbi.rafika@gmail.com>
Date: Thu, 27 Apr 2023 17:09:28 +0200
Message-ID: <CANx104ttKjkcUw-32NuCyT7bK0MoAixKKNO81V2krHFzp=ETDA@mail.gmail.com>
To: liste-egc@polytech.univ-nantes.fr, info-ic@inria.fr, bull-i3@irit.fr, 
	bull-ia@gdria.fr, dl@dl.kr.org, ln@groupes.renater.fr, Liste-proml@lri.fr, 
	web.semantique@inria.fr, "Event@CIG" <event@in.tu-clausthal.de>, sma@loria.fr, 
	agents@cs.umbc.edu, eda-liste <eda-liste@listes.univ-lyon2.fr>, 
	ml-news@googlegroups.com, ssfam@framalistes.org
Content-Type: multipart/alternative; boundary="000000000000eab46305fa52be72"
X-Validation-by: p_bruneau@hotmail.com
Subject: [liste-egc] [CFP] 1st ICDAR International workshop on Machine
 vision and NLP for Document Analysis (VINALDO)

--000000000000eab46305fa52be72
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

>
> Dear colleagues and researchers,
>
>
>
> *1st International workshop on Machine vision and NLP for Document
> Analysis (VINALDO)*
>
> *https://sites.google.com/view/vinaldo-workshop-icdar-2023/home*
> <https://sites.google.com/view/vinaldo-workshop-icdar-2023/home>
>
> *As part of the 17th International Conference on Document Analysis and
> Recognition*
>
> (ICDAR 2023)
>
> *https://icdar2023.org/
> <https://streaklinks.com/BXBi2-i9_SjRqQcRPgs5ZAqi/https%3A%2F%2Ficdar2023=
.org%2F?email=3Dboutalbi.rafika%40gmail.com>*
>
> *August 21-26, 2023 =E2=80=94 San Jos=C3=A9, California, USA*
>
>
>
> Context
>
> Document understanding is essential in various application areas such as
> data invoice extraction, subject review, medical prescription analysis,
> etc., and holds significant commercial potential. Several approaches are
> proposed in the literature, but datasets' availability and data privacy
> challenge it. Considering the problem of information extraction from
> documents, different aspects must be taken into account, such as (1)
> document classification, (2) text localization, (3) OCR (Optical Characte=
r
> Recognition), (4) table extraction, and (5) key information detection.
>
> In this context, machine vision and, more precisely, deep learning models
> for image processing are attractive methods. In fact, several models for
> document analysis were developed for text box detection, text extraction,
> table extraction, etc. Different kinds of deep learning approaches, such =
as
> GNN, are used to tackle these tasks. On the other hand, the extracted tex=
t
> from documents can be represented using different embeddings based on
> recent NLP approaches such as Transformers. Also, understanding spatial
> relationships is critical for text document extraction results for some
> applications such as invoice analysis.  Thus, the aim is to capture the
> structural connections between keywords (invoice number, date, amounts) a=
nd
> the main value (the desired information). An effective approach requires =
a
> combination of visual (spatial) and textual information.
>
> Objective
>
> The first edition of the machine VIsion and NAtural Language processing
> for DOcument analysis (VINALDO)  workshop comes as an extension of the
> GLESDO workshop, where we encourage the description of novel problems or
> applications for document analysis in the area of information retrieval
> that has emerged in recent years. We also encourage works that include NL=
P
> tools for extracted text, such as language models and Transforms.  Finall=
y,
> we also encourage works that develop new scanned document datasets for
> novel applications.
>
> The VINALDO workshop aims to bring together an area for industry, science=
,
> and academia experts to exchange ideas and discuss ongoing research in
> graph representation learning for scanned document analysis.
>
> Topics of interests
>
> We invite the submission of original works that are related -- but are no=
t
> limited to -- the topics below:
>
>    -
>
>    Document structure and layout learning
>    -
>
>    OCR based methods
>    -
>
>    Semi-supervised methods for document analysis
>    -
>
>    Dynamic graph analysis
>    -
>
>    Information Retrieval and Extraction form documents
>    -
>
>    Knowledge graph for semantic document analysis
>    -
>
>    Semantic understanding of document content
>    -
>
>    Entity and link prediction in graphs
>    -
>
>    Merging ontologies with graph-based methods using NLP techniques
>    -
>
>    Cleansing and image enhancement techniques for scanned document
>    -
>
>    Font text recognition in a scanned document
>    -
>
>    Table identification and extraction from scanned documents
>    -
>
>    Handwriting detection and recognition in documents
>    -
>
>    Signature detection and verification in documents
>    -
>
>    Visual document structure understanding
>    -
>
>    Visual Question Answering
>    -
>
>    Invoice analysis
>    -
>
>    Scanned documents classification
>    -
>
>    Scanned documents summarization
>    -
>
>    Scanned documents translation
>    -
>
>    Graph-based approaches for a spatial component in a scanned document
>    -
>
>    Graph representation learning for NLP
>
> Submission
>
> The workshop is open to original papers of theoretical or practical
> nature. Papers should be formatted according to LNCS instructions for
> authors
> <https://streaklinks.com/BaPft0cQ0AjwJZn7lAvT8yLc/https%3A%2F%2Fwww.sprin=
ger.com%2Ffr>.
> VINALDO 2023 will follow a double-blind review process. Authors should no=
t
> include their names and affiliations anywhere in the manuscript. Authors
> should also ensure that their identity is not revealed indirectly by citi=
ng
> their previous work in the third person and omitting acknowledgments unti=
l
> the camera-ready version. Papers have to be submitted via the workshop's
> EasyChair
> <https://streaklinks.com/BaPft0cmZn5QE4P6fgq4prXL/https%3A%2F%2Feasychair=
.org%2Fconferences%2F%3Fconf%3Dvinaldo1> submission
> page.
>
> We welcome the following types of contributions:
>
>    -
>
>    Full research papers (12-15 pages): Finished or consolidated R&D works
>    to be included in one of the Workshop topics
>    -
>
>    Short papers (6-8 pages): ongoing works with relevant preliminary
>    results, opened to discussion.
>
> At least one author of each accepted paper must register for the workshop
> in order to present the paper. For further instructions, please refer to =
the
>
> <https://streaklinks.com/BaPft0U0dGAGgr35vQQhY29o/https%3A%2F%2Fwww.googl=
e.com%2Furl%3Fq%3Dhttps%253A%252F%252Ficdar2021.org%252F%26sa%3DD%26sntz%3D=
1%26usg%3DAOvVaw0W4EcU263Y1GNomxyRFH3n>ICDAR
> 2023
> <https://streaklinks.com/BaPft0c6esXZ2-EjWQ9Vlysy/https%3A%2F%2Ficdar2023=
.org%2F>
>  page.
>
> Important dates
>
> *Submission Deadline: May 1st, 2023 at 11:59pm Pacific Time*
>
> Decisions Announced: May 28, 2023, at 11:59pm Pacific Time
>
> Camera Ready Deadline: June 4, 2023, at 11:59pm Pacific Time
>
> Workshop: August 24-26, 2023
>
> Workshop Chairs
>
> Rim Hantach
> <http://rim.hantach%40gmail.com%20%3Crim.hantach@gmail.com%3E%3B/>,
> Engie, France
>
> Rafika Boutalbi
> <https://streaklinks.com/BaPft0YTU38Y9_YkUgguo6qX/http%3A%2F%2Frafika.bou=
talbi%40univ-amu.fr%2F>,
> Aix-Marseille University, France
> =E1=90=A7
>

--000000000000eab46305fa52be72
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"auto"><div><div class=3D"gmail_quote"><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr"><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-=
family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px">Dear c=
olleagues and researchers,</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87=
);font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px"=
><span style=3D"font-weight:700">=C2=A0</span></p><p dir=3D"ltr" style=3D"c=
olor:rgba(0,0,0,0.87);font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-s=
erif;font-size:14px"><b>1st International workshop on=C2=A0Machine vision a=
nd NLP for Document Analysis=C2=A0(VINALDO)</b><span style=3D"font-weight:7=
00">=C2=A0</span></p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-fa=
mily:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px"><a href=
=3D"https://sites.google.com/view/vinaldo-workshop-icdar-2023/home" style=
=3D"color:rgb(41,98,255);text-decoration-line:none" rel=3D"noreferrer noref=
errer" target=3D"_blank"><span style=3D"text-decoration-line:underline"><b>=
https://sites.google.com/view/vinaldo-workshop-icdar-2023/home</b></span></=
a></p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-family:Roboto,Rob=
otoDraft,Helvetica,Arial,sans-serif;font-size:14px"><b>As part of the 17th=
=C2=A0International Conference on Document Analysis and Recognition</b></p>=
<p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-family:Roboto,RobotoDra=
ft,Helvetica,Arial,sans-serif;font-size:14px"><span style=3D"font-weight:70=
0">(ICDAR 2023)</span></p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);fo=
nt-family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px"><b>=
<a href=3D"https://streaklinks.com/BXBi2-i9_SjRqQcRPgs5ZAqi/https%3A%2F%2Fi=
cdar2023.org%2F?email=3Dboutalbi.rafika%40gmail.com" style=3D"color:rgb(41,=
98,255);text-decoration-line:none" rel=3D"noreferrer noreferrer" target=3D"=
_blank">https://icdar2023.org/</a></b></p><p dir=3D"ltr" style=3D"color:rgb=
a(0,0,0,0.87);font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;fon=
t-size:14px"><b>August 21-26, 2023 =E2=80=94 San Jos=C3=A9, California, USA=
</b><br></p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-family:Robo=
to,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px"><span style=3D"fo=
nt-weight:700">=C2=A0</span></p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.=
87);font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14p=
x"><span style=3D"font-weight:700">Context</span></p><p dir=3D"ltr" style=
=3D"color:rgba(0,0,0,0.87);font-family:Roboto,RobotoDraft,Helvetica,Arial,s=
ans-serif;font-size:14px">Document understanding is essential in various ap=
plication areas such as data invoice extraction, subject review, medical pr=
escription analysis, etc., and holds significant commercial potential. Seve=
ral approaches are proposed in the literature, but datasets&#39; availabili=
ty and data privacy challenge it. Considering the problem of information ex=
traction from documents, different aspects must be taken into account, such=
 as (1) document classification, (2) text localization, (3) OCR (Optical Ch=
aracter Recognition), (4) table extraction, and (5) key information detecti=
on.=C2=A0</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-family:Rob=
oto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px">In this context,=
 machine vision and, more precisely, deep learning models for image process=
ing are attractive methods. In fact, several models for document analysis w=
ere developed for text box detection, text extraction, table extraction, et=
c. Different kinds of deep learning approaches, such as GNN, are used to ta=
ckle these tasks. On the other hand, the extracted text from documents can =
be represented using different embeddings based on recent NLP approaches su=
ch as Transformers. Also, understanding spatial relationships is critical f=
or text document extraction results for some applications such as invoice a=
nalysis.=C2=A0 Thus, the aim is to capture the structural connections betwe=
en keywords (invoice number, date, amounts) and the main value (the desired=
 information). An effective approach requires a combination of visual (spat=
ial) and textual information.=C2=A0</p><p dir=3D"ltr" style=3D"color:rgba(0=
,0,0,0.87);font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-s=
ize:14px"><span style=3D"font-weight:700">Objective</span></p><p dir=3D"ltr=
" style=3D"color:rgba(0,0,0,0.87);font-family:Roboto,RobotoDraft,Helvetica,=
Arial,sans-serif;font-size:14px">The first edition of the=C2=A0machine VIsi=
on and NAtural Language processing for DOcument analysis (VINALDO)=C2=A0=C2=
=A0workshop comes as an extension of the GLESDO workshop, where we encourag=
e the description of novel problems or applications for document analysis i=
n the area of information retrieval that has emerged in recent years. We al=
so encourage works that include NLP tools for extracted text, such as langu=
age models and Transforms.=C2=A0 Finally, we also encourage works that deve=
lop new scanned document datasets for novel applications.</p><div style=3D"=
font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px"><=
div><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87)">The VINALDO workshop ai=
ms to bring together an area for industry, science, and academia experts to=
 exchange ideas and discuss ongoing research in graph representation learni=
ng for scanned document analysis.</p><p dir=3D"ltr" style=3D"color:rgba(0,0=
,0,0.87)"><span style=3D"font-weight:700">Topics of interests</span></p><p =
dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87)">We invite the submission of or=
iginal works that are related -- but are not limited to -- the topics below=
:</p><ul style=3D"color:rgba(0,0,0,0.87)"><li dir=3D"ltr" style=3D"margin-l=
eft:15px"><p dir=3D"ltr">Document structure and layout learning=C2=A0</p></=
li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">OCR based meth=
ods=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr"=
>Semi-supervised methods for document analysis</p></li><li dir=3D"ltr" styl=
e=3D"margin-left:15px"><p dir=3D"ltr">Dynamic graph analysis=C2=A0</p></li>=
<li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">Information Retri=
eval and Extraction form documents=C2=A0</p></li><li dir=3D"ltr" style=3D"m=
argin-left:15px"><p dir=3D"ltr">Knowledge graph for semantic document analy=
sis=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr"=
>Semantic understanding of document content=C2=A0</p></li><li dir=3D"ltr" s=
tyle=3D"margin-left:15px"><p dir=3D"ltr">Entity and link prediction in grap=
hs=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">=
Merging ontologies with graph-based methods using NLP techniques=C2=A0</p><=
/li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">Cleansing and=
 image enhancement techniques for scanned document=C2=A0</p></li><li dir=3D=
"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">Font text recognition in a =
scanned document=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><=
p dir=3D"ltr">Table identification and extraction from scanned documents=C2=
=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">Handw=
riting detection and recognition in documents=C2=A0</p></li><li dir=3D"ltr"=
 style=3D"margin-left:15px"><p dir=3D"ltr">Signature detection and verifica=
tion in documents=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px">=
<p dir=3D"ltr">Visual document structure understanding=C2=A0</p></li><li di=
r=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">Visual Question Answeri=
ng=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">=
Invoice analysis=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><=
p dir=3D"ltr">Scanned documents classification=C2=A0</p></li><li dir=3D"ltr=
" style=3D"margin-left:15px"><p dir=3D"ltr">Scanned documents summarization=
=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">Sc=
anned documents translation=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-l=
eft:15px"><p dir=3D"ltr">Graph-based approaches for a spatial component in =
a scanned document=C2=A0</p></li><li dir=3D"ltr" style=3D"margin-left:15px"=
><p dir=3D"ltr">Graph representation learning for NLP</p></li></ul><p dir=
=3D"ltr" style=3D"color:rgba(0,0,0,0.87)"><span style=3D"font-weight:700">S=
ubmission</span></p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87)">The wor=
kshop is open to original papers of theoretical or practical nature. Papers=
 should be formatted=C2=A0according to=C2=A0<span style=3D"text-decoration-=
line:underline"><a href=3D"https://streaklinks.com/BaPft0cQ0AjwJZn7lAvT8yLc=
/https%3A%2F%2Fwww.springer.com%2Ffr" style=3D"color:rgb(41,98,255);text-de=
coration-line:none" rel=3D"noreferrer noreferrer" target=3D"_blank">LNCS in=
structions for authors</a></span>. VINALDO=C2=A02023=C2=A0will follow a dou=
ble-blind review process. Authors should not include their names and affili=
ations anywhere in the manuscript. Authors should also ensure that their id=
entity is not revealed indirectly by citing their previous work in the thir=
d person and omitting acknowledgments until the camera-ready version.=C2=A0=
Papers=C2=A0have=C2=A0to be submitted=C2=A0via the workshop&#39;s=C2=A0<spa=
n style=3D"text-decoration-line:underline"><a href=3D"https://streaklinks.c=
om/BaPft0cmZn5QE4P6fgq4prXL/https%3A%2F%2Feasychair.org%2Fconferences%2F%3F=
conf%3Dvinaldo1" style=3D"color:rgb(41,98,255);text-decoration-line:none" r=
el=3D"noreferrer noreferrer" target=3D"_blank">EasyChair</a></span>=C2=A0su=
bmission page.</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87)">We welcom=
e the following types of contributions:</p><ul style=3D"color:rgba(0,0,0,0.=
87)"><li dir=3D"ltr" style=3D"margin-left:15px"><p dir=3D"ltr">Full researc=
h papers (12-15 pages):=C2=A0Finished or consolidated R&amp;D works to be i=
ncluded in one of the Workshop topics</p></li><li dir=3D"ltr" style=3D"marg=
in-left:15px"><p dir=3D"ltr">Short papers (6-8 pages):=C2=A0ongoing works w=
ith relevant preliminary results, opened to discussion.</p></li></ul><p dir=
=3D"ltr" style=3D"color:rgba(0,0,0,0.87)">At least one author of each accep=
ted paper must register for the workshop in order to present the paper.=C2=
=A0For further instructions, please refer to the<a href=3D"https://streakli=
nks.com/BaPft0U0dGAGgr35vQQhY29o/https%3A%2F%2Fwww.google.com%2Furl%3Fq%3Dh=
ttps%253A%252F%252Ficdar2021.org%252F%26sa%3DD%26sntz%3D1%26usg%3DAOvVaw0W4=
EcU263Y1GNomxyRFH3n" style=3D"color:rgb(41,98,255);text-decoration-line:non=
e" rel=3D"noreferrer noreferrer" target=3D"_blank">=C2=A0</a><a href=3D"htt=
ps://streaklinks.com/BaPft0c6esXZ2-EjWQ9Vlysy/https%3A%2F%2Ficdar2023.org%2=
F" hspace=3D"streak-track" style=3D"color:rgb(41,98,255);text-decoration-li=
ne:none" rel=3D"noreferrer noreferrer" target=3D"_blank">ICDAR 2023</a>=C2=
=A0page.</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87)"><span style=3D"=
font-weight:700">Important dates</span></p><p dir=3D"ltr"><b><font color=3D=
"#000000" style=3D"background-color:rgb(255,153,0)">Submission Deadline: Ma=
y 1st, 2023 at 11:59pm Pacific Time</font></b></p><p dir=3D"ltr" style=3D"c=
olor:rgba(0,0,0,0.87)">Decisions Announced: May 28, 2023, at 11:59pm Pacifi=
c Time</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87)">Camera Ready Dead=
line: June 4, 2023, at 11:59pm Pacific Time</p></div></div><p style=3D"colo=
r:rgba(0,0,0,0.87);font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-seri=
f;font-size:14px">Workshop: August 24-26, 2023</p><p dir=3D"ltr" style=3D"c=
olor:rgba(0,0,0,0.87);font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-s=
erif;font-size:14px"><span style=3D"font-weight:700">Workshop Chairs</span>=
</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-family:Roboto,Robot=
oDraft,Helvetica,Arial,sans-serif;font-size:14px"><span style=3D"font-weigh=
t:700"><a href=3D"http://rim.hantach%40gmail.com%20%3Crim.hantach@gmail.com=
%3E%3B/" hspace=3D"streak-track" style=3D"color:rgb(41,98,255);text-decorat=
ion-line:none" rel=3D"noreferrer noreferrer" target=3D"_blank">Rim Hantach<=
/a></span>, Engie, France</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87)=
;font-family:Roboto,RobotoDraft,Helvetica,Arial,sans-serif;font-size:14px">=
</p><p dir=3D"ltr" style=3D"color:rgba(0,0,0,0.87);font-family:Roboto,Robot=
oDraft,Helvetica,Arial,sans-serif;font-size:14px"><span style=3D"font-weigh=
t:700"><a href=3D"https://streaklinks.com/BaPft0YTU38Y9_YkUgguo6qX/http%3A%=
2F%2Frafika.boutalbi%40univ-amu.fr%2F" hspace=3D"streak-track" style=3D"col=
or:rgb(41,98,255);text-decoration-line:none" rel=3D"noreferrer noreferrer" =
target=3D"_blank">Rafika Boutalbi</a></span>, Aix-Marseille University, Fra=
nce</p></div><div hspace=3D"streak-pt-mark" style=3D"max-height:1px"><img a=
lt=3D"" style=3D"width:0px;max-height:0px;overflow:hidden" src=3D"https://m=
ailfoogae.appspot.com/t?sender=3DaYm91dGFsYmkucmFmaWthQGdtYWlsLmNvbQ%3D%3D&=
amp;type=3Dzerocontent&amp;guid=3D55e520b7-b600-420b-825c-a99747a28d82"><fo=
nt color=3D"#ffffff" size=3D"1">=E1=90=A7</font></div>
</blockquote></div></div></div>

--000000000000eab46305fa52be72--
