Return-Path: <p_bruneau@hotmail.com>
X-Original-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Received: from bouncesmtp2.univ-nantes.fr (bouncesmtp2.u12.univ-nantes.prive [172.20.12.67])
	by sympa62.u12.univ-nantes.prive (Postfix) with ESMTP id 9E32A14014F0
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Tue, 15 Nov 2022 13:19:10 +0100 (CET)
Received: from mx2.localdomain (MX2.univ-nantes.fr [193.52.101.136])
	by bouncesmtp2.univ-nantes.fr (Postfix) with ESMTP id 9AB7965D5
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Tue, 15 Nov 2022 13:19:10 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
	by mx2.localdomain (Postfix) with ESMTP id 937391015DD
	for <liste-egc@polytech.univ-nantes.fr>; Tue, 15 Nov 2022 13:19:10 +0100 (CET)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: -9.778
X-Spam-Level:
X-Spam-Status: No, score=-9.778 tagged_above=-1000 required=5
	tests=[CRM114_UNSURE=0.1, HTML_MESSAGE=0.001, NO_RDNS2=0.01,
	RCVD_IN_DNSWL_MED=-10, RCVD_IN_WSFF=0.01, SPF_HELO_NONE=0.001,
	SPF_PASS=-0.001, UN_PHISHING_PW=0.1, URIBL_BLOCKED=0.001]
	autolearn=disabled
X-CRM114-Status: UNSURE ( -4.3507 )
X-CRM114-CacheID: 
Received: from mx2.localdomain ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id H6sqPK-Gl4bk for <liste-egc@polytech.univ-nantes.fr>;
	Tue, 15 Nov 2022 13:19:04 +0100 (CET)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from oxalide-smtp-out.extra.cea.fr (oxalide-smtp-out.extra.cea.fr [132.168.224.13])
	by mx2.localdomain (Postfix) with ESMTPS id 1DC951015D8
	for <liste-egc@polytech.univ-nantes.fr>; Tue, 15 Nov 2022 13:19:04 +0100 (CET)
Received: from pisaure.intra.cea.fr (pisaure.intra.cea.fr [132.166.88.21])
	by oxalide-sys.extra.cea.fr (8.14.7/8.14.7/CEAnet-Internet-out-4.0) with ESMTP id 2AFCIr89029713;
	Tue, 15 Nov 2022 13:18:53 +0100
Received: from pisaure.intra.cea.fr (localhost [127.0.0.1])
	by localhost (Postfix) with SMTP id 57949207E05;
	Tue, 15 Nov 2022 13:18:53 +0100 (CET)
Received: from muguet2-smtp-out.intra.cea.fr (muguet2-smtp-out.intra.cea.fr [132.166.192.13])
	by pisaure.intra.cea.fr (Postfix) with ESMTP id 40871207E02;
	Tue, 15 Nov 2022 13:18:53 +0100 (CET)
Received: from I-EXCH-A3.intra.cea.fr (i-exch-a3.intra.cea.fr [132.166.88.227])
	by muguet2-sys.intra.cea.fr (8.14.7/8.14.7/CEAnet-Internet-out-4.0) with ESMTP id 2AFCIra2035972;
	Tue, 15 Nov 2022 13:18:53 +0100
Received: from I-EXCH-B1.intra.cea.fr (132.166.88.235) by
 I-EXCH-A3.intra.cea.fr (132.166.88.227) with Microsoft SMTP Server
 (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256) id
 15.1.2507.12; Tue, 15 Nov 2022 13:18:52 +0100
Received: from I-EXCH-B1.intra.cea.fr ([132.166.88.235]) by
 I-EXCH-B1.intra.cea.fr ([132.166.88.235]) with mapi id 15.01.2507.012; Tue,
 15 Nov 2022 13:18:52 +0100
From: POPESCU Adrian <adrian.popescu@cea.fr>
To: "liste-egc@polytech.univ-nantes.fr" <liste-egc@polytech.univ-nantes.fr>,
        "bull-i3@irit.fr" <bull-i3@irit.fr>,
        "info-ic@listes.irisa.fr"
	<info-ic@listes.irisa.fr>,
        "ln@cines.fr" <ln@cines.fr>,
        "liste-proml@lri.fr"
	<liste-proml@lri.fr>
Thread-Topic: Call for Papers - ICMR 2023 - International Conference on
 Multimedia Retrieval
Thread-Index: AQHY+OxsOJfVtRbfe0yiwjt9l+qstg==
Date: Tue, 15 Nov 2022 12:18:52 +0000
Message-ID: <415ae3aea257464da4920c3e2cfc8190@cea.fr>
References: <7daf3c96-b1ca-63e6-437c-159d49ec0dcd@iti.gr>
In-Reply-To: <7daf3c96-b1ca-63e6-437c-159d49ec0dcd@iti.gr>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [132.167.194.33]
x-tm-as-product-ver: SMEX-14.0.0.3080-9.0.1002-27264.007
x-tm-as-result: No-10--23.791200-8.000000
x-tmase-matchedrid: 6HMoliKXreg25XOhnouJ5RuurbgYp+HQCCo+lsDuynVL/3rQmWrTBjgo
	8pDHL4T+2jLjTN2/0fpT0gFhwwXJ3aaDx0F8sKdXYrc32n84WHq87rU89eLPKaq68ZuK1qe4LRB
	qPTlFOygbrGfTO9RvaJVrrQyBZ96Q4OzMl+rTYhEvcCFTz9CqagYAPqHoVmYRiEiOvN7JAwrzWM
	gQWjC6I+UMe3w2tyxA5JI7RhwVP+uUkDPUhpX2vpV3j1zTOBYzY/8hgefJn7BFpKl8aBgi1zwcz
	pIGNrAI0wMtJG+/C3u1DyyGkZkjc4d1E9CxClKsrZZaiLezul0BqNb4Qv6VoyD/D93AcAyThNYA
	Dd9MA1FNBi/q20S4hs7+1PqsZabR8OmA2ojZaC1V8scx1YOQqH3mRGxgQm4WX4EGuK4lRYQjEmz
	RAq1CW81j70qfy418xjrpG6Mci47LTKToLArG4hQ7ky03us3DoR62RNvkvOvkwebMz3zHYrcKse
	gEgav5nEwQ8IYl7MTVMJCZKkTk5VazYtukrpqmZg+ljEMYai6uP3jhainBqs4tlnb0ey8wvX+fE
	guafahV6acwlOfZcdUwkJkqROTl3svEHVae6LxD4HTrR22wI0vYVBWf/pQJvsuGOPOyHAGAmEIC
	68Fs1+D5CIcLwXN6WZnHQ3mL8NelBA8TvXlsKh1kSRHxj+Z5MVx/3ZYby7/ksrI0CdrN+uLSdVP
	2tZn5z4cHo4nKdPGzK4j1ZmqkLMEThpH3DgaTa87CDXaKRVJZDdHiTk9OcDTf96WBdPMjxAaY6M
	FYVEe8Hwj72YScJxUl2sGcM2xyhiDgqKzqD7+rm7DrUlmNkH8mA3sDDq0A1JB10kVk7oUfZMPNH
	XeG7tNldGim1ZRQLgYyK8bYvg5hBjkojTOnB5x6lNUQ0j8hrTbZKW2oaMg=
x-tm-as-user-approved-sender: Yes
x-tm-as-user-blocked-sender: No
x-tmase-result: 10--23.791200-8.000000
x-tmase-version: SMEX-14.0.0.3080-9.0.1002-27264.007
x-tm-snts-smtp: DF0930C7E046AC2B167B07CE35700919AEA9FCF1BE37738418E567A355114F1B2000:8
Content-Type: multipart/alternative;
	boundary="_000_415ae3aea257464da4920c3e2cfc8190ceafr_"
MIME-Version: 1.0
X-Validation-by: p_bruneau@hotmail.com
Subject: [liste-egc] Call for Papers - ICMR 2023 - International Conference
 on Multimedia Retrieval

--_000_415ae3aea257464da4920c3e2cfc8190ceafr_
Content-Type: text/plain; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable


*********************************************************
ACM International Conference on Multimedia Retrieval 2023
Thessaloniki, Greece, 12 - 15 June 2023
Web: https://icmr2023.org/
**********************************************************
_______________

CALL FOR PAPERS
_______________

ACM ICMR 2023 is calling for high quality original papers addressing
innovative research in multimedia retrieval and its related broad
fields. The main scope of the conference is not only search and
retrieval of multimedia data but also analysis and understanding of
multimedia contents including community-contributed social data,
lifelogging data and automatically generated sensor data, integration of
diverse multimodal data, deep learning-based methodology and practical
multimedia applications.

Long research papers should present complete work with evaluations on
topics related to the Conference. They will have both oral and poster
presentations at the conference. Authors of the best papers will be
offered an opportunity to extend their work for a Special Issue in a
peer-reviewed multimedia journal (to be defined). Short research papers
should present preliminary results or more focused contributions. They
will be presented as posters at the conference.

Topics of Interest

     -Multimedia content-based search and retrieval,
     -Multimedia-content-based (or hybrid) recommender systems,
     -Large-scale and Web-scale multimedia retrieval,
     -Multimedia content extraction, analysis, and indexing,
     -Multimedia analytics and knowledge discovery,
     -Multimedia machine learning, deep learning, and neural networks,
     -Relevance feedback, active learning, and transfer learning,
     -Fine-grained retrieval for multimedia,
     -Event-based indexing and multimedia understanding,
     -Semantic descriptors and novel high- or mid-level features,
     -Crowdsourcing, community contributions, and social multimedia,
     -Multimedia retrieval leveraging quality, production cues, style,
framing, and affect,
     -Synthetic media generation and detection,
     -Narrative generation and narrative analysis,
     -User intent and human perception in multimedia retrieval,
     -Query processing and relevance feedback,
     -Multimedia browsing, summarization, and visualization,
     -Multimedia beyond video, including 3D data and sensor data,
     -Mobile multimedia browsing and search,
     -Multimedia analysis/search acceleration, e.g., GPU, FPGA,
     -Benchmarks and evaluation methodologies for multimedia
analysis/search,
     -Privacy-aware multimedia retrieval methods and systems,
     -Fairness and explainability in multimedia analysis/search,
     -Legal, ethical and societal impact of multimedia retrieval research,
     -Applications of multimedia retrieval, e.g., news/journalism,
media, medicine, sports, commerce, lifelogs, travel, security, and
environment.

_____________________

SUBMISSION GUIDELINES
_____________________

Maximum Length of a Paper

Long research paper: Each long research paper should not be longer than
8 pages, plus additional pages for the list of references.

Short research paper: Each short research paper should not be longer
than 4 pages, plus additional pages for the list of references.

_______________

IMPORTANT DATES
_______________

Paper Submission Due: January 31, 2023
Notification of Acceptance: March 31, 2023
Camera-Ready Papers Due: April 17, 2023

______________

REVIEW PROCESS
______________


ACM ICMR follows a double-blind review process for full paper selection.
Authors should not know the names of the reviewers of their papers, and
reviewers should not know the name(s) of the author(s). Please prepare
your paper in a way that preserves anonymity of the authors:

     Do not put your names under the title,
     Avoid using phrases such as =93our previous work=94 when referring to
earlier publications by the authors,
     Remove information that may identify the authors in the
acknowledgments (e.g., co-workers and grant IDs),
     Check supplemental material for information that may identify the
authors=92 identity,
     Avoid providing links to Websites that identify the authors.

Abstract and Keywords

The abstract and the keywords form the primary source for assigning
papers to reviewers. So make sure that they form a concise and complete
summary of your paper with sufficient information to let someone who has
not read the full paper know what it is about.

Submission Instructions: https://icmr2023.org/paper-submissions/

_______

CONTACT
_______

For any question regarding full and short paper submissions, please
visit the conference website (icmr2023.org) or email the Program Chairs:

     Vasileios Mezaris, Centre for Research and Technology Hellas,
Greece (bmezaris@iti.gr)
     Symeon Papadopoulos, Centre for Research and Technology Hellas,
Greece (papadop@iti.gr)
     Adrian Popescu, CEA LIST, France (adrian.popescu@cea.fr)
     Zi (Helen) Huang, University of Queensland, Australia
(huang@itee.uq.edu.au)

############################


Unsubscribe:

SIGIR-signoff-request@LISTSERV.ACM.ORG

If you don't already have a password for the LISTSERV.ACM.ORG server, we re=
commend
that you create one now. A LISTSERV password is linked to your email
address and can be used to access the web interface and all the lists to
which you are subscribed on the LISTSERV.ACM.ORG server.

To create a password, visit:

https://LISTSERV.ACM.ORG/SCRIPTS/WA-ACMLPX.CGI?GETPW1

Once you have created a password, you can log in and view or change your
subscription settings at:

https://LISTSERV.ACM.ORG/SCRIPTS/WA-ACMLPX.CGI?SUBED1=3DSIGIR

--_000_415ae3aea257464da4920c3e2cfc8190ceafr_
Content-Type: text/html; charset="Windows-1252"
Content-Transfer-Encoding: quoted-printable

<html>
<head>
<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3DWindows-1=
252">
<style type=3D"text/css" style=3D"display:none;"><!-- P {margin-top:0;margi=
n-bottom:0;} --></style>
</head>
<body dir=3D"ltr">
<div id=3D"divtagdefaultwrapper" style=3D"font-size:12pt;color:#000000;font=
-family:Calibri,Helvetica,sans-serif;" dir=3D"ltr">
<br>
<font size=3D"2"><span style=3D"font-size:10pt;"></span></font>
<div style=3D"color: rgb(0, 0, 0);"><font size=3D"2"><span style=3D"font-si=
ze:10pt;">
<div class=3D"PlainText">**************************************************=
*******<br>
ACM International Conference on Multimedia Retrieval 2023<br>
Thessaloniki, Greece, 12 - 15 June 2023<br>
Web: <a href=3D"https://icmr2023.org/" id=3D"LPlnk863846" previewremoved=3D=
"true">https://icmr2023.org/</a><br>
**********************************************************<br>
_______________<br>
<br>
CALL FOR PAPERS<br>
_______________<br>
<br>
ACM ICMR 2023 is calling for high quality original papers addressing <br>
innovative research in multimedia retrieval and its related broad <br>
fields. The main scope of the conference is not only search and <br>
retrieval of multimedia data but also analysis and understanding of <br>
multimedia contents including community-contributed social data, <br>
lifelogging data and automatically generated sensor data, integration of <b=
r>
diverse multimodal data, deep learning-based methodology and practical <br>
multimedia applications.<br>
<br>
Long research papers should present complete work with evaluations on <br>
topics related to the Conference. They will have both oral and poster <br>
presentations at the conference. Authors of the best papers will be <br>
offered an opportunity to extend their work for a Special Issue in a <br>
peer-reviewed multimedia journal (to be defined). Short research papers <br=
>
should present preliminary results or more focused contributions. They <br>
will be presented as posters at the conference.<br>
<br>
Topics of Interest<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia content-based search and retrieval,<br=
>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia-content-based (or hybrid) recommender =
systems,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Large-scale and Web-scale multimedia retrieval,<b=
r>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia content extraction, analysis, and inde=
xing,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia analytics and knowledge discovery,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia machine learning, deep learning, and n=
eural networks,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Relevance feedback, active learning, and transfer=
 learning,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Fine-grained retrieval for multimedia,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Event-based indexing and multimedia understanding=
,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Semantic descriptors and novel high- or mid-level=
 features,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Crowdsourcing, community contributions, and socia=
l multimedia,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia retrieval leveraging quality, producti=
on cues, style, <br>
framing, and affect,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Synthetic media generation and detection,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Narrative generation and narrative analysis,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -User intent and human perception in multimedia re=
trieval,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Query processing and relevance feedback,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia browsing, summarization, and visualiza=
tion,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia beyond video, including 3D data and se=
nsor data,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Mobile multimedia browsing and search,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Multimedia analysis/search acceleration, e.g., GP=
U, FPGA,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Benchmarks and evaluation methodologies for multi=
media <br>
analysis/search,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Privacy-aware multimedia retrieval methods and sy=
stems,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Fairness and explainability in multimedia analysi=
s/search,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Legal, ethical and societal impact of multimedia =
retrieval research,<br>
&nbsp;&nbsp;&nbsp;&nbsp; -Applications of multimedia retrieval, e.g., news/=
journalism, <br>
media, medicine, sports, commerce, lifelogs, travel, security, and <br>
environment.<br>
<br>
_____________________<br>
<br>
SUBMISSION GUIDELINES<br>
_____________________<br>
<br>
Maximum Length of a Paper<br>
<br>
Long research paper: Each long research paper should not be longer than <br=
>
8 pages, plus additional pages for the list of references.<br>
<br>
Short research paper: Each short research paper should not be longer <br>
than 4 pages, plus additional pages for the list of references.<br>
<br>
_______________<br>
<br>
IMPORTANT DATES<br>
_______________<br>
<br>
Paper Submission Due: January 31, 2023<br>
Notification of Acceptance: March 31, 2023<br>
Camera-Ready Papers Due: April 17, 2023<br>
<br>
______________<br>
<br>
REVIEW PROCESS<br>
______________<br>
<br>
<br>
ACM ICMR follows a double-blind review process for full paper selection. <b=
r>
Authors should not know the names of the reviewers of their papers, and <br=
>
reviewers should not know the name(s) of the author(s). Please prepare <br>
your paper in a way that preserves anonymity of the authors:<br>
<br>
&nbsp;&nbsp;&nbsp;&nbsp; Do not put your names under the title,<br>
&nbsp;&nbsp;&nbsp;&nbsp; Avoid using phrases such as =93our previous work=
=94 when referring to <br>
earlier publications by the authors,<br>
&nbsp;&nbsp;&nbsp;&nbsp; Remove information that may identify the authors i=
n the <br>
acknowledgments (e.g., co-workers and grant IDs),<br>
&nbsp;&nbsp;&nbsp;&nbsp; Check supplemental material for information that m=
ay identify the <br>
authors=92 identity,<br>
&nbsp;&nbsp;&nbsp;&nbsp; Avoid providing links to Websites that identify th=
e authors.<br>
<br>
Abstract and Keywords<br>
<br>
The abstract and the keywords form the primary source for assigning <br>
papers to reviewers. So make sure that they form a concise and complete <br=
>
summary of your paper with sufficient information to let someone who has <b=
r>
not read the full paper know what it is about.<br>
<br>
Submission Instructions: <a href=3D"https://icmr2023.org/paper-submissions/=
" id=3D"LPlnk135502" previewremoved=3D"true">
https://icmr2023.org/paper-submissions/</a><br>
<br>
_______<br>
<br>
CONTACT<br>
_______<br>
<br>
For any question regarding full and short paper submissions, please <br>
visit the conference website (icmr2023.org) or email the Program Chairs:<br=
>
<br>
&nbsp;&nbsp;&nbsp;&nbsp; Vasileios Mezaris, Centre for Research and Technol=
ogy Hellas, <br>
Greece (bmezaris@iti.gr)<br>
&nbsp;&nbsp;&nbsp;&nbsp; Symeon Papadopoulos, Centre for Research and Techn=
ology Hellas, <br>
Greece (papadop@iti.gr)<br>
&nbsp;&nbsp;&nbsp;&nbsp; Adrian Popescu, CEA LIST, France (adrian.popescu@c=
ea.fr)<br>
&nbsp;&nbsp;&nbsp;&nbsp; Zi (Helen) Huang, University of Queensland, Austra=
lia <br>
(huang@itee.uq.edu.au)<br>
<br>
############################<br>
<br>
<br>
Unsubscribe:<br>
<br>
SIGIR-signoff-request@LISTSERV.ACM.ORG<br>
<br>
If you don't already have a password for the LISTSERV.ACM.ORG server, we re=
commend<br>
that you create one now. A LISTSERV password is linked to your email<br>
address and can be used to access the web interface and all the lists to<br=
>
which you are subscribed on the LISTSERV.ACM.ORG server.<br>
<br>
To create a password, visit:<br>
<br>
<a href=3D"https://LISTSERV.ACM.ORG/SCRIPTS/WA-ACMLPX.CGI?GETPW1" id=3D"LPl=
nk891694" previewremoved=3D"true">https://LISTSERV.ACM.ORG/SCRIPTS/WA-ACMLP=
X.CGI?GETPW1</a><br>
<br>
Once you have created a password, you can log in and view or change your<br=
>
subscription settings at:<br>
<br>
<a href=3D"https://LISTSERV.ACM.ORG/SCRIPTS/WA-ACMLPX.CGI?SUBED1=3DSIGIR" i=
d=3D"LPlnk663496" previewremoved=3D"true">https://LISTSERV.ACM.ORG/SCRIPTS/=
WA-ACMLPX.CGI?SUBED1=3DSIGIR</a><br>
</div>
</span></font></div>
</div>
</body>
</html>

--_000_415ae3aea257464da4920c3e2cfc8190ceafr_--
