Return-Path: <p_bruneau@hotmail.com>
X-Original-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Received: from BounceSmtp1.univ-nantes.fr (BounceSMTP1.univ-nantes.prive [172.20.12.66])
	by sympa62.u12.univ-nantes.prive (Postfix) with ESMTP id 81E1614014E0
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Wed,  4 Mar 2020 11:24:20 +0100 (CET)
Received: from mx3.d101.univ-nantes.fr (MX3.univ-nantes.fr [193.52.101.137])
	by BounceSmtp1.univ-nantes.fr (Postfix) with ESMTP id 806CD6D19C6
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Wed,  4 Mar 2020 11:24:20 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
	by mx3.d101.univ-nantes.fr (Postfix) with ESMTP id 7BDDC40106CD
	for <liste-egc@polytech.univ-nantes.fr>; Wed,  4 Mar 2020 11:24:20 +0100 (CET)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: 0
X-Spam-Level:
X-Spam-Status: No, score=x tagged_above=-1000 required=5 WHITELISTED tests=[]
	autolearn=unavailable
Received: from mx3.d101.univ-nantes.fr ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id RpxLVuV3ebGX for <liste-egc@polytech.univ-nantes.fr>;
	Wed,  4 Mar 2020 11:24:20 +0100 (CET)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from mail2-relais-roc.national.inria.fr (mail2-relais-roc.national.inria.fr [192.134.164.83])
	by mx3.d101.univ-nantes.fr (Postfix) with ESMTPS id 5A877402F3A4
	for <liste-egc@polytech.univ-nantes.fr>; Wed,  4 Mar 2020 11:24:20 +0100 (CET)
X-IronPort-AV: E=Sophos;i="5.70,513,1574118000"; 
   d="scan'208,217";a="438748186"
Received: from solal.irisa.fr ([131.254.10.161])
  by mail2-relais-roc.national.inria.fr with ESMTP/TLS/DHE-RSA-AES256-SHA; 04 Mar 2020 11:24:19 +0100
From: Elisa Fromont <elisa.fromont@irisa.fr>
Message-ID: <c9e3b8b4-a22a-a251-1240-28606b798296@irisa.fr>
Date: Wed, 4 Mar 2020 11:24:19 +0100
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:68.0)
 Gecko/20100101 Thunderbird/68.5.0
MIME-Version: 1.0
To: destinataires inconnus: ;
Content-Type: multipart/alternative;
 boundary="------------9DA108B88CAB1A5310978EA4"
Content-Language: en-GB
X-Validation-by: p_bruneau@hotmail.com
Subject: [liste-egc] Job offer - Inria post-doc (2 years) - "Hybrid
 Approaches for Interpretable AI"

This is a multi-part message in MIME format.
--------------9DA108B88CAB1A5310978EA4
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

Hello,


A post-doc job offer is available here:
https://jobs.inria.fr/public/classic/fr/offres/2020-02332


Here is a summary:


Applications are welcome for a *post-doctoral position* at Inria as part 
of the HyAIAI Inria "Défi" <https://project.inria.fr/hyaiai/>. More 
specifically, this position is part of a collaboration between the 
Lacodam and SequeL Inria teams. The post-doc will share her time between 
the two groups (Lacodam <https://team.inria.fr/lacodam/>in Rennes, 
SequeL <https://team.inria.fr/sequel/>in Lille). She will actively 
participate in the activities of HyAIAI, in particular reporting on her 
work in the HYAIAI meetings.

The main purpose of this post-doctoral fellowship is to port the 
principles of interpretable AI and ML to the domain of the *visual 
question answering*. Attaining such a goal requires us to overcome other 
challenges such as understanding what makes a good explanation in a 
multi-modal setting.


    Background

*Visual Question Answering (VQA) *is a research area concerned with the 
construction of computer systems that can answer questions in natural 
language from the contents of an image. VQA carries potential 
applications in multimodal information retrieval.

Current VQA solutions rely on deep learning techniques. Being a problem 
on multimodal data, this implies to merge both images and questions into 
a common representation space. This is challenging because images and 
texts are very different data types, treated by means of different 
neural network architectures: CNNs (Convolutional Neural Networks) are 
the state of the art for image classification and representation, 
whereas text processing often resorts to RNNs (Recurrent Neural 
Networks). VQA solutions must orchestrate both technologies leading to 
systems that are extremely complex.

The complexity of existing VQA solutions makes the task of inspection 
and debugging very hard. In particular, neural networks are black-box 
models: one requires a significant amount of work and solid expertise to 
understand the inner-workings of the network. It becomes therefore very 
difficult to understand why a VQA system makes a mistake. Such a task, 
however, is vital for the progress of research in VQA.


Contact for more information:

Philippe Preux (philippe.preux@inria.fr <mailto:philippe.preux@inria.fr>)
Luis Galárraga (luis.galarraga@inria.fr <mailto:luis.galarraga@inria.fr>)

-- 
Elisa Fromont
Professor Université Rennes 1, member of LACODAM research team at IRISA
IRISA (UMR 6074), Campus de Beaulieu, 35042 Rennes cedex, France
web: http://people.irisa.fr/Elisa.Fromont/
tel: 33 2 99 84 73 14
email: elisa.fromont@irisa.fr


--------------9DA108B88CAB1A5310978EA4
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 8bit

<html>
  <head>

    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  </head>
  <body>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">Hello,</span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;"><br>
      </span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">A
        post-doc job offer is available here: </span><br>
      <span style="font-weight: 400;" data-mce-style="font-weight: 400;"><a class="moz-txt-link-freetext" href="https://jobs.inria.fr/public/classic/fr/offres/2020-02332">https://jobs.inria.fr/public/classic/fr/offres/2020-02332</a></span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;"><br>
      </span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">Here
        is a summary:<br>
      </span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;"><br>
      </span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">Applications
        are welcome for a <b>post-doctoral position</b> at Inria as
        part of the </span><a href="https://project.inria.fr/hyaiai/"
        data-mce-href="https://project.inria.fr/hyaiai/"
        moz-do-not-send="true"><span style="font-weight: 400;"
          data-mce-style="font-weight: 400;">HyAIAI Inria "Défi"</span></a><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">.
        More specifically, this position is part of a collaboration
        between the Lacodam and SequeL Inria teams. The post-doc will
        share her time between the two groups (</span><a
        href="https://team.inria.fr/lacodam/"
        data-mce-href="https://team.inria.fr/lacodam/"><span
          style="font-weight: 400;" data-mce-style="font-weight: 400;">Lacodam</span></a><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;"> in
        Rennes, </span><a href="https://team.inria.fr/sequel/"
        data-mce-href="https://team.inria.fr/sequel/"><span
          style="font-weight: 400;" data-mce-style="font-weight: 400;">SequeL</span></a><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;"> in
        Lille). She will actively participate in the activities of
        HyAIAI, in particular reporting on her work in the HYAIAI
        meetings.</span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">The
        main purpose of this post-doctoral fellowship is to port the
        principles of interpretable AI and ML to the domain of the <b>visual
          question answering</b>. Attaining such a goal requires us to
        overcome other challenges such as understanding what makes a
        good explanation in a multi-modal setting. <br>
      </span></p>
    <h2>Background</h2>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><strong>Visual
        Question Answering (VQA) </strong><span style="font-weight:
        400;" data-mce-style="font-weight: 400;">is a research area
        concerned with the construction of computer systems that can
        answer questions in natural language from the contents of an
        image. VQA carries potential applications in multimodal
        information retrieval. <br>
      </span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">Current
        VQA solutions rely on deep learning techniques. Being a problem
        on multimodal data, this implies to merge both images and
        questions into a common representation space. This is
        challenging because images and texts are very different data
        types, treated by means of different neural network
        architectures: CNNs (Convolutional Neural Networks) are the
        state of the art for image classification and representation,
        whereas text processing often resorts to RNNs (Recurrent Neural
        Networks). VQA solutions must orchestrate both technologies
        leading to systems that are extremely complex.</span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">The
        complexity of existing VQA solutions makes the task of
        inspection and debugging very hard. In particular, neural
        networks are black-box models: one requires a significant amount
        of work and solid expertise to understand the inner-workings of
        the network. It becomes therefore very difficult to understand
        why a VQA system makes a mistake. Such a task, however, is vital
        for the progress of research in VQA.   <br>
      </span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;"><br>
      </span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;">Contact
        for more information:</span></p>
    <p><span style="font-weight: 400;">Philippe Preux (</span><a
        href="mailto:philippe.preux@inria.fr"><span style="font-weight:
          400;">philippe.preux@inria.fr</span></a><span
        style="font-weight: 400;">)</span><span style="font-weight:
        400;"><span style="font-weight: 400;"><br>
          Luis Galárraga (</span><a
          href="mailto:luis.galarraga@inria.fr"><span
            style="font-weight: 400;">luis.galarraga@inria.fr</span></a><span
          style="font-weight: 400;">)</span></span></p>
    <p style="text-align: justify; margin: 0px;"
      data-mce-style="text-align: justify; margin: 0px;"><span
        style="font-weight: 400;" data-mce-style="font-weight: 400;"></span></p>
    <pre class="moz-signature" cols="72">-- 
Elisa Fromont
Professor Université Rennes 1, member of LACODAM research team at IRISA
IRISA (UMR 6074), Campus de Beaulieu, 35042 Rennes cedex, France
web: <a class="moz-txt-link-freetext" href="http://people.irisa.fr/Elisa.Fromont/">http://people.irisa.fr/Elisa.Fromont/</a>
tel: 33 2 99 84 73 14
email: <a class="moz-txt-link-abbreviated" href="mailto:elisa.fromont@irisa.fr">elisa.fromont@irisa.fr</a></pre>
  </body>
</html>

--------------9DA108B88CAB1A5310978EA4--
