Return-Path: <sylvain.gelly@gmail.com>
X-Original-To: polytech_liste-egc@sympa.univ-nantes.fr
Delivered-To: polytech_liste-egc@sympa.univ-nantes.fr
Received: from BounceSmtp2.univ-nantes.fr (BounceSMTP2.univ-nantes.prive [172.20.12.67])
	by Sympa.univ-nantes.fr (Postfix) with ESMTP id A76A31A23302
	for <polytech_liste-egc@sympa.univ-nantes.fr>; Thu, 13 Sep 2007 23:16:08 +0200 (CEST)
Received: from MX3.univ-nantes.fr (MX3.univ-nantes.fr [193.52.101.137])
	by BounceSmtp2.univ-nantes.fr (Postfix) with ESMTP id 95E61C1AF
	for <polytech_liste-egc@sympa.univ-nantes.fr>; Thu, 13 Sep 2007 23:03:09 +0200 (CEST)
Received: from localhost (debian [127.0.0.1])
	by MX3.univ-nantes.fr (Postfix) with ESMTP id 8AB311C0AB0D
	for <polytech_liste-egc@sympa.univ-nantes.fr>; Thu, 13 Sep 2007 23:16:08 +0200 (CEST)
Received: from MX3.univ-nantes.fr ([193.52.101.137])
	by localhost (MX3.univ-nantes.fr [193.52.101.137]) (amavisd-new, port 10024)
	with LMTP id 01137-02-28
	for <polytech_liste-egc@sympa.univ-nantes.fr>;
	Thu, 13 Sep 2007 23:16:04 +0200 (CEST)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from wx-out-0506.google.com (wx-out-0506.google.com [66.249.82.235])
	by MX3.univ-nantes.fr (Postfix) with ESMTP id BB5541C00C41
	for <liste-egc@polytech.univ-nantes.fr>; Thu, 13 Sep 2007 23:16:03 +0200 (CEST)
Received: by wx-out-0506.google.com with SMTP id t5so547788wxc
        for <liste-egc@polytech.univ-nantes.fr>; Thu, 13 Sep 2007 14:16:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=beta;
        h=domainkey-signature:received:received:message-id:date:from:sender:to:subject:mime-version:content-type:content-transfer-encoding:content-disposition:x-google-sender-auth;
        bh=ZM7XqRwiszfeN9ahuEamu5ZI5QwNT6AQQnlXcbI4bAk=;
        b=Bmgm5IQJGxSwevHTeWG211wkUAdfSjGam6dU8oN+NMNdzVE9NbjjglTPQX8uBjbMJIDSlPb5vtMNO/mg+LiITlGru8fxU03AabAiQg2KUsoexmcSGZ9AfccTioly3Scq+aixF/aqWUgywPiauM+f2v6WvjJiC1jZTUe+QrSkCxw=
DomainKey-Signature: a=rsa-sha1; c=nofws;
        d=gmail.com; s=beta;
        h=received:message-id:date:from:sender:to:subject:mime-version:content-type:content-transfer-encoding:content-disposition:x-google-sender-auth;
        b=BG7ym3kVqDloFCBNSRS8OSmx7z3ROyW45CLI903oZN4Y7LOH72TtxY972RigA/SUuBpsByi+8KlQ2Rmd33aNMTqS9JrFMWa6S+6qq7KFYS6jBn0yPbqCnFmr1T28eFt39+gBJ+/I1Iy+1VxLZ8oUNr9Cn1qaGTsjvf8CeyfsUUg=
Received: by 10.90.49.1 with SMTP id w1mr952684agw.1189718162348;
        Thu, 13 Sep 2007 14:16:02 -0700 (PDT)
Received: by 10.90.84.16 with HTTP; Thu, 13 Sep 2007 14:16:02 -0700 (PDT)
Message-ID: <f88574740709131416v7a1bfb55j6d878ad58344e44c@mail.gmail.com>
Date: Thu, 13 Sep 2007 23:16:02 +0200
From: "Sylvain Gelly" <sylvain.gelly@m4x.org>
Sender: sylvain.gelly@gmail.com
To: liste-egc@polytech.univ-nantes.fr
Subject: =?ISO-8859-1?Q?Soutenance_de_th=E8se_de_Sylvain_Gelly?=
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline
X-Google-Sender-Auth: ac1ffb46acb97cc1
X-Virus-Scanned: by amavisd-new-20030616-p7 (Debian) at univ-nantes.fr
X-CRM114-Version: 20040816.BlameClockworkOrange-auto.3 (regex: TRE TRE 0.7.2 (GPL)) MF-A10FFB4C 
X-CRM114-Status: Good  ( pR: 20.7418 )
X-Spam-Status: No, hits=-4.4 tagged_above=-10000.0 required=5.0
	tests=SARE_MSGID_LONG40, CRM_HAM_05
X-Spam-Level: 
X-Validation-by: fabrice.guillet@univ-nantes.fr

Bonjour,

J'ai le plaisir de vous inviter =E0 assister =E0 ma soutenance de th=E8se i=
ntitul=E9e
   "Une contribution a l'apprentissage par renforcement ;
application au computer go".

La soutenance aura lieu le Mardi 25 septembre 2007 =E0 14h30 au
Laboratoire de Recherche en Informatique (LRI), salle 79, b=E2timent
490, sur le campus d'Orsay de l'Universit=E9 Paris-Sud 11

Devant le jury compos=E9 de :

- BLANC-TALON Jacques (Examinateur), DGA
- BOUSQUET Olivier (Examinateur), Google
- BREDECHE Nicolas (Co-directeur de th=E8se), Univ. Paris 11
- MUNOS R=E9mi (Rapporteur), INRIA Futurs Lille
- SEBAG Mich=E8le (Directrice de th=E8se),  CNRS
- SHAW-TAYLOR John (Examinateur), University College London
- SZEPESVARI Csaba (Rapporteur), University of Alberta

Cordialement,
Sylvain Gelly

R=E9sum=E9 en francais:

Le domaine de l'Apprentissage par Renforcement (AR) se trouve =E0
l'interface entre la th=E9orie du contr=F4le, l'apprentissage supervis=E9 et
non-supervis=E9, l'optimisation et les sciences cognitives, et est un
domaine tr=E8s actif de par ses applications et les probl=E8mes non r=E9sol=
us.
Cette th=E8se apporte quelques contributions dans ce domaine,
principalement sur trois axes. Le 1er axe correspond =E0 la mod=E9lisation
de l'environnement, i.e. =E0 l'apprentissage de la fonction de transition
entre deux pas de temps. L'apprentissage et l'utilisation de ce mod=E8le
se fait efficacement dans les approches factoris=E9es. Les R=E9seaux
Bayesiens sont un moyen de repr=E9senter ce type de mod=E8le, et dans ce
domaine le travail pr=E9sent=E9 propose un nouveau crit=E8re d'apprentissag=
e,
=E0 la fois pour le param=E9trique (probabilit=E9s conditionnelles) et
non-param=E9trique (structure). Le 2=E8me axe est une =E9tude du cas de l'AR
en continu (espace d'=E9tat et d'action), =E0 partir de l'algorithme de
r=E9solution par programmation dynamique. Cette analyse s'attaque =E0 trois
=E9tapes fondamentales de cet algorithme: l'optimisation (choix de
l'action =E0 partir de la fonction de valeurs (FV)), l'apprentissage
supervis=E9 (regression) de la FV et le choix des exemples sur lesquels
apprendre (apprentissage actif). Le 3=E8me axe de contribution correspond
au domaine applicatif du jeu de Go, qui est un cas discret et de grande
dimension qui reste un grand challenge pour les algorithmes d'AR. Dans
ce domaine, les algorithmes utilis=E9s et am=E9lior=E9s ont permis au
programme r=E9sultant, MoGo de gagner de nombreuses comp=E9titions
internationales et devenant par exemple le premier programme jouant =E0 un
niveau dan amateur sur plateau 9x9.



R=E9sum=E9 en anglais:

Reinforcement Learning (RL) is at the interface of control theory,
supervised and unsupervised learning, optimization and cognitive
sciences. While RL addresses many objectives with major economic impact,
it raises deep theoretical and practical difficulties. This thesis
brings some contributions to RL, mainly on three axis. The first axis
corresponds to environment modeling, i.e. learning the transition
function between two time steps. Factored approaches give an efficiently
framework for the learning and use of this model. The Bayesian Networks
are a tool to represent such a model, and this work brings new learning
criterion, either in parametric learning (conditional probabilities) and
non parametric (structure). The second axis is a study in continuous
space and action RL, thanks to the dynamic programming algorithm. This
analysis tackles three fundamental steps: optimization (action choice
from the value function), supervised learning (regression) of the value
function and choice of the learning examples (active learning). The
third axis tackles the applicative domain of the game of Go, as a high
dimensional discrete control problem, one of the greatest challenge in
Machine Learning. The presented algorithms with their improvements made
the resulting program, MoGo, win numerous international competitions,
becoming for example the first go program playing at an amateur dan
level on 9x9.

