Return-Path: <Laure.Soulier@irit.fr>
X-Original-To: polytech_liste-egc@sympa6.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa6.univ-nantes.prive
Received: from BounceSmtp1.univ-nantes.fr (BounceSMTP1.univ-nantes.prive [172.20.12.66])
	by sympa6.univ-nantes.prive (Postfix) with ESMTP id 53F881903CC0
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Mon, 18 May 2015 11:51:46 +0200 (CEST)
Received: from mx2.d101.univ-nantes.fr (MX2.univ-nantes.fr [193.52.101.136])
	by BounceSmtp1.univ-nantes.fr (Postfix) with ESMTP id 4637C700DB
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Mon, 18 May 2015 11:51:46 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mx2.d101.univ-nantes.fr (Postfix) with ESMTP id 4293633DAB
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 18 May 2015 11:51:46 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: -9.778
X-Spam-Level:
X-Spam-Status: No, score=-9.778 tagged_above=-1000 required=5
	tests=[CRM114_UNSURE=0.1, DNS_FROM_AHBL_RHSBL=0.01,
	HTML_MESSAGE=0.001, RCVD_IN_DNSWL_MED=-10, RCVD_IN_WSFF=0.01,
	UNPARSEABLE_RELAY=0.001, UN_PHISHING_PW=0.1] autolearn=disabled
X-CRM114-Status: UNSURE ( 3.9895 )
X-CRM114-CacheID: 
Received: from mx2.d101.univ-nantes.fr ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id OJcx6YuuAxzC for <liste-egc@polytech.univ-nantes.fr>;
	Mon, 18 May 2015 11:51:44 +0200 (CEST)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from smtp1.cict.fr (smtp1.cict.fr [195.220.59.41])
	by mx2.d101.univ-nantes.fr (Postfix) with ESMTP id 5AEEF629F0E5
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 18 May 2015 11:51:43 +0200 (CEST)
Received: from smtp1.cict.fr (localhost.localdomain [127.0.0.1])
	by smtp1.cict.fr (8.14.5/8.14.4) with ESMTP id t4I9pgh2005023
	for <liste-egc@polytech.univ-nantes.fr>; Mon, 18 May 2015 11:51:43 +0200
Received: from smtp1.irit.fr (smtp1.irit.fr [141.115.24.2])
	by smtp1.cict.fr (8.14.5/8.14.5) with ESMTP id t4I9pf4f004985;
	Mon, 18 May 2015 11:51:42 +0200
Received: from irit.fr
Message-ID: <5559B60B.6070204@irit.fr>
Date: Mon, 18 May 2015 11:51:07 +0200
From: "Laure.Soulier" <Laure.Soulier@irit.fr>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.6.0
MIME-Version: 1.0
To: bull-i3@irit.fr, liste-egc@polytech.univ-nantes.fr,
        info-ic <info-ic@listes.irisa.fr>, info-aria@lsis.org,
        docs-ri-subscribe@yahoogroupes.fr
Content-Type: multipart/alternative;
 boundary="------------010802010308040400020007"
X-Virus-Scanned: clamav-milter 0.97.3 at smtp1.cict.fr
X-Virus-Status: Clean
X-Validation-by: cyril.de-runz@univ-reims.fr
Subject: [liste-egc] 2nd CFP for ECol'15. Workshop on Evaluation of
 Collaborative Information Retrieval and Seeking - CIKM 2015 - DEADLINE
 EXTENSION JUNE 12th

This is a multi-part message in MIME format.
--------------010802010308040400020007
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

******* Apologies if you receive multiple copies of this message *******


==========================================================

ECol Workshop @ CIKM’2015: Call for papers - *Deadline extension: June 
12, 2015*

==========================================================

The 1st International Workshop on the

Evaluation of Collaborative Information Retrieval and Seeking ECol'2015
in conjunction with the 24th ACM International Conference on Information 
and Knowledge Management (CIKM)

Melbourne, Australia, October 23, 2015

http://www.irit.fr/ECol2015/
=========================================================

OVERVIEW

The paradigm of CIS/CIR refers to methodologies and technologies that 
support collective-knowledge sharing within a work team in order to 
solve a shared complex problem. One main challenge in CIS/CIR is to 
satisfy the mutual beneficial goals of both individual users and the 
collaborative group while maintaining a reasonable level of cognitive 
effort. In previous work, CIS/CIR evaluation relies on simulation-based 
protocols, user or log-based studies and metrics leveraging the 
individual vs. collaborative dimensions of search effectiveness. The 
most common evaluation strategy is to undertake both qualitative and 
quantitative evaluation according to the search tasks characteristics 
and evaluation objectives such as cognitive effort, usability, and 
individual vs. collective effectiveness. However, to date and to our 
knowledge, although substantial research advances in the evaluation of 
plenty information retrieval and seeking tasks have been achieved 
through international evaluation campaigns such as TREC, CLEF and NTCIR, 
no standardization effort has been achieved for the evaluation of 
CIS/CIR. We believe therein that there is an important need to 
investigate the evaluation challenge in CIS/CIR with the hope of 
building standardized evaluation frameworks that would foster the 
research area.

SCOPE AND TOPICS

Both theoretical and practical research papers are welcome from both 
research and industrial communities addressing the main conference 
topic,  but will also consider related aspects including models, 
methods, techniques and examples of CIS/CIR in theory and in practice. 
Original and unpublished papers are welcome on any aspect including:

  * CIS/CIR evaluation framework design and implementation
  * System-based vs. user-based evaluation approaches for CIS/CIR
  * Novel or extended traditional evaluation measures, test collections,
    methodologies of operational evaluation.
  * Models and methods of and for CIS/CIR
  * Impact of the collaborative session temporal synchronicity on the
    evaluation
  *   Evaluation of domain application-oriented CIS/CIR: exploratory
    search, travel planning, education project, legal and medical domain...
  * Evaluation of specific collaborative tasks (search, sensemaking,
    intent understanding…)
  * Studies on collective relevance judging
  * Studies of collaborative behavior applicable to evaluation
  * Simulation vs. log-studies vs. user-studies for collaborative search
  * Evaluation of single vs. collaborative search session
  * Connections to related research in contextual and interactive
    information seeking and retrieval
  * Evaluation Concerns and Issues: Reliability, Repeatability,
    Reproducibility, Replicability
  * Proposed evaluation tasks and collections for CIS/CIR



IMPORTANT DATES

Paper Submission:*June 12, 2015 (deadline extension)*
Notification of Acceptance: July 23, 2015
Camera-Ready papers due: August 7, 2015
Workshop: October 23, 2015




PAPER SUBMISSION AND GUIDELINES

The submissions will be peer reviewed (double blind) and should be no 
longer than 4 pages in the ACM format 
(http://www.acm.org/sigs/publications/proceedings-templates). The papers 
should be submitted online through the EasyChair workshop submission 
system at:**https://easychair.org/conferences/?conf=ecol2015. All 
submitted papers will  be peer-reviewed by at least two members of the 
workshop program committee. At least one author of each accepted paper 
must attend the workshop to present the paper. All accepted papers will 
be published in the workshop proceedings published by CEUR. For more 
information, please see the workshop website http://www.irit.fr/ECol2015/


ORGANIZERS

     •    Leif Azzopardi, School of Computing Science at the University 
of Glasgow - UK (Leif.Azzopardi@glasgow.ac.uk)
     •    Jeremy Pickens, Catalyst Repository Systems - USA 
(jpickens@catalystsecure.com)
     •    Tetsuya Sakai, Waseda University - Japan (tetsuyasakai@acm.org)
     •    Laure Soulier, Paul Sabatier University - IRI, France 
(Laure.Soulier@irit.fr)
     •    Lynda Tamine-Lechani, Paul Sabatier University - IRIT, France 
(Lynda.Tamine-Lechani@irit.fr)



INVITED SPEAKERS

To be announced


PROGRAM COMMITTEE

To be announced



--------------010802010308040400020007
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 8bit

<html>
  <head>

    <meta http-equiv="content-type" content="text/html; charset=utf-8">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    <div class="moz-text-html" lang="x-unicode"> ******* Apologies if
      you receive multiple copies of this message *******<br>
      <br>
      <br>
      <div class="moz-forward-container">
        <div class="moz-forward-container">
          ==========================================================<br>
          <br>
          ECol Workshop @ CIKM’2015: Call for papers - <b>Deadline
            extension: June 12, 2015</b><br>
          <br>
          ==========================================================<br>
          <br>
          The 1st International Workshop on the<br>
          <br>
          Evaluation of Collaborative Information Retrieval and Seeking
          ECol'2015<br>
          in conjunction with the 24th ACM International Conference on
          Information and Knowledge Management (CIKM)<br>
          <br>
          Melbourne, Australia, October 23, 2015<br>
          <br>
          <a moz-do-not-send="true" class="moz-txt-link-freetext"
            href="http://www.irit.fr/ECol2015/">http://www.irit.fr/ECol2015/</a>
          <br>
          =========================================================<br>
          <br>
          OVERVIEW<br>
          <br>
          The paradigm of CIS/CIR refers to methodologies and
          technologies that support collective-knowledge sharing within
          a work team in order to solve a shared complex problem. One
          main challenge in CIS/CIR is to satisfy the mutual beneficial
          goals of both individual users and the collaborative group
          while maintaining a reasonable level of cognitive effort. In
          previous work, CIS/CIR evaluation relies on simulation-based
          protocols, user or log-based studies and metrics leveraging
          the individual vs. collaborative dimensions of search
          effectiveness. The most common evaluation strategy is to
          undertake both qualitative and quantitative evaluation
          according to the search tasks characteristics and evaluation
          objectives such as cognitive effort, usability, and individual
          vs. collective effectiveness. However, to date and to our
          knowledge, although substantial research advances in the
          evaluation of plenty information retrieval and seeking tasks
          have been achieved through international evaluation campaigns
          such as TREC, CLEF and NTCIR, no standardization effort has
          been achieved for the evaluation of CIS/CIR. We believe
          therein that there is an important need to investigate the
          evaluation challenge in CIS/CIR with the hope of building
          standardized evaluation frameworks that would foster the
          research area. <br>
          <br>
          SCOPE AND TOPICS<br>
          <br>
          Both theoretical and practical research papers are welcome
          from both research and industrial communities addressing the
          main conference topic,  but will also consider related aspects
          including models, methods, techniques and examples of CIS/CIR
          in theory and in practice. Original and unpublished papers are
          welcome on any aspect including:<br>
          <br>
          <ul>
            <li> CIS/CIR evaluation framework design and implementation
            </li>
            <li> System-based vs. user-based evaluation approaches for
              CIS/CIR</li>
            <li> Novel or extended traditional evaluation measures, test
              collections, methodologies of operational evaluation.</li>
            <li> Models and methods of and for CIS/CIR</li>
            <li> Impact of the collaborative session temporal
              synchronicity on the evaluation</li>
            <li> Evaluation of domain application-oriented CIS/CIR:
              exploratory search, travel planning, education project,
              legal and medical domain...</li>
            <li> Evaluation of specific collaborative tasks (search,
              sensemaking, intent understanding…)</li>
            <li> Studies on collective relevance judging</li>
            <li> Studies of collaborative behavior applicable to
              evaluation</li>
            <li> Simulation vs. log-studies vs. user-studies for
              collaborative search</li>
            <li> Evaluation of single vs. collaborative search session</li>
            <li> Connections to related research in contextual and
              interactive information seeking and retrieval</li>
            <li> Evaluation Concerns and Issues: Reliability,
              Repeatability, Reproducibility, Replicability</li>
            <li> Proposed evaluation tasks and collections for CIS/CIR</li>
          </ul>
          <br>
          <br>
          IMPORTANT DATES<br>
          <br>
          Paper Submission:<font color="#ff0000"><b> June 12, 2015
              (deadline extension)</b></font><br>
          Notification of Acceptance: July 23, 2015<br>
          Camera-Ready papers due: August 7, 2015<br>
          Workshop: October 23, 2015<br>
          <br>
          <br>
          <br>
          <br>
          PAPER SUBMISSION AND GUIDELINES<br>
          <br>
          The submissions will be peer reviewed (double blind) and
          should be no longer than 4 pages in the ACM format (<a
            moz-do-not-send="true" class="moz-txt-link-freetext"
            href="http://www.acm.org/sigs/publications/proceedings-templates">http://www.acm.org/sigs/publications/proceedings-templates</a>).




          The papers should be submitted online through the EasyChair
          workshop submission system at:<b> </b><span><a
              moz-do-not-send="true" class="moz-txt-link-freetext"
              href="https://easychair.org/conferences/?conf=ecol2015">https://easychair.org/conferences/?conf=ecol2015</a></span>.
          All submitted papers will  be peer-reviewed by at least two
          members of the workshop program committee. At least one author
          of each accepted paper must attend the workshop to present the
          paper. All accepted papers will be published in the workshop
          proceedings published by CEUR. For more information, please
          see the workshop website <a moz-do-not-send="true"
            class="moz-txt-link-freetext"
            href="http://www.irit.fr/ECol2015/">http://www.irit.fr/ECol2015/</a>
          <br>
          <br>
          <br>
          ORGANIZERS<br>
          <br>
              •    Leif Azzopardi, School of Computing Science at the
          University of Glasgow - UK (<a moz-do-not-send="true"
            class="moz-txt-link-abbreviated"
            href="mailto:Leif.Azzopardi@glasgow.ac.uk">Leif.Azzopardi@glasgow.ac.uk</a>)<br>
              •    Jeremy Pickens, Catalyst Repository Systems - USA (<a
            moz-do-not-send="true" class="moz-txt-link-abbreviated"
            href="mailto:jpickens@catalystsecure.com">jpickens@catalystsecure.com</a>)<br>
              •    Tetsuya Sakai, Waseda University - Japan (<a
            moz-do-not-send="true" class="moz-txt-link-abbreviated"
            href="mailto:tetsuyasakai@acm.org">tetsuyasakai@acm.org</a>)<br>
              •    Laure Soulier, Paul Sabatier University - IRI, France
          (<a moz-do-not-send="true" class="moz-txt-link-abbreviated"
            href="mailto:Laure.Soulier@irit.fr">Laure.Soulier@irit.fr</a>)<br>
              •    Lynda Tamine-Lechani, Paul Sabatier University -
          IRIT, France (<a moz-do-not-send="true"
            class="moz-txt-link-abbreviated"
            href="mailto:Lynda.Tamine-Lechani@irit.fr">Lynda.Tamine-Lechani@irit.fr</a>)<br>
          <br>
          <br>
          <br>
          INVITED SPEAKERS<br>
          <br>
          To be announced<br>
          <br>
          <br>
          PROGRAM COMMITTEE<br>
          <br>
          To be announced <br>
        </div>
        <br>
      </div>
      <br>
    </div>
  </body>
</html>

--------------010802010308040400020007--
