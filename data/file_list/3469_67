Return-Path: <p_bruneau@hotmail.com>
X-Original-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Received: from bouncesmtp2.univ-nantes.fr (BounceSMTP2.univ-nantes.prive [172.20.12.67])
	by sympa62.u12.univ-nantes.prive (Postfix) with ESMTP id 4C06614017E3
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Tue, 22 Mar 2022 09:04:54 +0100 (CET)
Received: from mx3.d101.univ-nantes.fr (MX3.univ-nantes.fr [193.52.101.137])
	by bouncesmtp2.univ-nantes.fr (Postfix) with ESMTP id 485E25F9B
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Tue, 22 Mar 2022 09:04:54 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
	by mx3.d101.univ-nantes.fr (Postfix) with ESMTP id 41BE520911
	for <liste-egc@polytech.univ-nantes.fr>; Tue, 22 Mar 2022 09:04:54 +0100 (CET)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: -2.868
X-Spam-Level:
X-Spam-Status: No, score=-2.868 tagged_above=-1000 required=5
	tests=[CRM114_GOOD=-5, DKIM_SIGNED=0.1, DKIM_VALID=-0.1,
	DKIM_VALID_AU=-0.1, DKIM_VALID_EF=-0.1, HTML_MESSAGE=0.001,
	J_BACKHAIR_41=1, J_BACKHAIR_45=1, MR_NOT_ATTRIBUTED_IP=0.2,
	NO_RDNS2=0.01, RCVD_IN_WSFF=0.01, SPF_HELO_NONE=0.001,
	SPF_PASS=-0.001, T_REMOTE_IMAGE=0.01, UN_PHISHING_PW=0.1,
	URIBL_BLOCKED=0.001] autolearn=disabled
X-CRM114-Status: GOOD ( 14.4312 )
X-CRM114-CacheID: 
Authentication-Results: univ-nantes.fr (amavisd-new); dkim=pass (1024-bit key)
	header.d=unicaen.fr
Received: from mx3.d101.univ-nantes.fr ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id cOxsdARfpL8f for <liste-egc@polytech.univ-nantes.fr>;
	Tue, 22 Mar 2022 09:04:51 +0100 (CET)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from mailout.unicaen.fr (mailoutvip1.unicaen.fr [194.199.107.40])
	by mx3.d101.univ-nantes.fr (Postfix) with ESMTP id A73FA201FF
	for <liste-egc@polytech.univ-nantes.fr>; Tue, 22 Mar 2022 09:04:51 +0100 (CET)
Received: from wzproxy2.unicaen.fr (wzproxy2.unicaen.fr [193.55.120.53])
	by mailout.unicaen.fr (Postfix) with ESMTP id 80AF480AA5;
	Tue, 22 Mar 2022 09:04:51 +0100 (CET)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=unicaen.fr; s=mail;
	t=1647936291; bh=oerjn9aG16xU/1STYuBcakU4CRTgfPjnOnk+a6P1Uyw=;
	h=From:Subject:Date:To:From;
	b=TjU094CFII55xLk+iBHOJnwSWg8YBe4ovo5bUKK6ZS6LZPCvR6PaP6mN1bM+P78Dj
	 YR1ZlnT3/aWFd80apef648E0Wh2yk2Lenb5JFvSpgtBQYvMFnsQlQum+MosAKjubvq
	 6pEAW2cqz4s7CkBx+FLYRmDh1VzIiviqBFEMEsSs=
Received: from localhost (localhost [127.0.0.1])
	by wzproxy2.unicaen.fr (Postfix) with ESMTP id 78DEF66C85;
	Tue, 22 Mar 2022 09:04:51 +0100 (CET)
X-Amavis-Modified: Mail body modified (using disclaimer) - wzproxy2.unicaen.fr
X-Virus-Scanned: amavisd-new at wzproxy2.unicaen.fr
Received: from wzproxy2.unicaen.fr ([127.0.0.1])
	by localhost (wzproxy2.unicaen.fr [127.0.0.1]) (amavisd-new, port 10026)
	with ESMTP id uGRPB45w_3V8; Tue, 22 Mar 2022 09:04:51 +0100 (CET)
Received: from lsmtp2.unicaen.fr (lsmtp2.unicaen.fr [193.55.120.33])
	by wzproxy2.unicaen.fr (Postfix) with ESMTP id 4AF5A66830;
	Tue, 22 Mar 2022 09:04:51 +0100 (CET)
Received: from n302l-g21p05.info.unicaen.fr (n302l-g21p05.info.unicaen.fr [10.130.144.221])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by lsmtp2.unicaen.fr (Postfix) with ESMTPSA id F034B7D4FD22A;
	Tue, 22 Mar 2022 09:04:42 +0100 (CET)
From: lezoray <olivier.lezoray@unicaen.fr>
Content-Type: multipart/alternative;
	boundary="Apple-Mail=_93ECBF97-1B91-49F4-97D0-7BC8DF9606FD"
Mime-Version: 1.0 (Mac OS X Mail 13.4 \(3608.120.23.2.7\))
Message-Id: <B4829B91-ED2D-41B9-A5E1-A397A3567BBA@unicaen.fr>
Date: Tue, 22 Mar 2022 09:04:42 +0100
To: info-ic@listes.irisa.fr,
 liste-egc@polytech.univ-nantes.fr,
 bull-ia@gdria.fr,
 bull-i3@irit.fr,
 visionlist@visionscience.com,
 cvnet@mail.ewind.com,
 multicomm@comsoc.org
X-Mailer: Apple Mail (2.3608.120.23.2.7)
X-Validation-by: p_bruneau@hotmail.com
Subject: [liste-egc] PhD position at University of Caen, CNRS GREYC
 Laboratory on "Frugal AI for image segmentation"


--Apple-Mail=_93ECBF97-1B91-49F4-97D0-7BC8DF9606FD
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=utf-8

=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
PhD position at University of Caen, CNRS GREYC Laboratory
on "Frugal AI for image segmentation"
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D

Topic
-----

The advent of deep learning has been a real tsunami in the machine =
learning community, leading to results, especially in computer vision, =
that we would not have expected a few years before. For many vision =
tasks, the performances of deep learning algorithms have become =
equivalent or even superior to human performances.

However, these results have been obtained at the cost of ever-increasing =
use of resources such as: the size of the model, the time and energy =
needed to train them, with ever-larger databases and ever-higher =
annotation requirements. This increase in resource requirements has =
major drawbacks, related to the impact that ML has on the environment, =
the difficulty to implement models on embedded architectures, or the =
challenges raised when models have to be trained on tasks for which =
little training data is available.

These observations have very recently led some authors [1, 2] to =
introduce the concept of frugal machine learning and to define what a =
frugal machine learning methodology should be, and how to evaluate =
frugality.

In this dissertation, we will study frugality in the context of AI for =
image segmentation [3]. The objective will be to propose frugal models =
that can provide efficient results while being structured to provide a =
reduced time and space complexity. More precisely, we will consider =
several aspects of frugality and take inspiration from the following =
recent works : i) the conception of lightweight models by design [4, 5] =
ii) the compression of existing models [6] iii) the pruning of existing =
segmentation models [4, 7] iv) frugality on image label and zero shot =
image segmentation [8, 9].

Qualifications
--------------

Candidates must have an MSc or engineering degree in a field related to =
computer science, electrical engineering, or applied mathematics, with =
strong programming skills (in particular with deep learning frameworks). =
Experience with image processing will be a plus. Candidates are expected =
to have abilities to write scientific reports and communicate research =
results at conferences in English.

Information and application
---------------------------

The position is starting as soon as possible with a salary of 32 kEuros =
gross, and will be located in Caen, France.

Applications should include the following documents in electronic =
format: i) A short motivation letter stating why you are interested in =
this project, ii) A detailed CV describing your past research background =
related to the position iii) The transcripts for master degrees. iv) The =
contact information for three references (do not include the reference =
letters with your applications as we will only ask for the reference =
letters for short-listed candidates).

Please send your application package to frederic.jurie@unicaen.fr =
<mailto:frederic.jurie@unicaen.fr>   and olivier.lezoray@unicaen.fr =
<mailto:olivier.lezoray@unicaen.fr>=20

Ideally located in the heart of Normandy, two hours from Paris and just =
10 minutes away from the beaches, Caen, William the Conqueror=E2=80=99s =
hometown, is a lively and dynamic city.


References
----------

[1] Lingjiao Chen, Matei Zaharia, and James Y. Zou, =E2=80=9CFrugalML : =
How to use ML Prediction APIs more accurately and cheaply,=E2=80=9D in =
Advances in Neural Information Processing Systems 33 : Annual Conference =
on Neural Information Processing Systems 2020, NeurIPS 2020, December =
6-12, 2020, Virtual, Hugo Larochelle, Marc=E2=80=99Aurelio Ranzato, Raia =
Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, Eds., 2020.
[2] Mikhail Evchenko, Joaquin Vanschoren, Holger H. Hoos, Marc =
Schoenauer, and Mich=C3=A8le Sebag, =E2=80=9CFrugal Machine Learning,=E2=80=
=9D arXiv :2111.03731 [cs, eess], Nov. 2021.
[3] Shervin Minaee, Yuri Y. Boykov, Fatih Porikli, Antonio J Plaza, =
Nasser Kehtarnavaz, and Demetri Terzopoulos, =E2=80=9CImage segmentation =
using deep learning : A survey,=E2=80=9D IEEE Transactions on Pattern =
Analysis and Machine Intelligence, pp. 1=E2=80=931, 2021.
[4] Linjie Wang, Quan Zhou, Chenfeng Jiang, Xiaofu Wu, and Longin  Jan =
Latecki, =E2=80=9CDRBANET: A Lightweight Dual-Resolution Network for =
Semantic Segmentation with Boundary Auxiliary,=E2=80=9D arXiv =
:2111.00509 [cs], Oct. 2021.
[5] Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. =
Alvarez, and Ping Luo, =E2=80=9CSegformer : Simple and efficient design =
for semantic segmentation with transformers,=E2=80=9D CoRR, vol. =
abs/2105.15203, 2021.
[6] Moonjung Eo, Suhyun Kang, and Wonjong Rhee, =E2=80=9CA Highly =
Effective Low-Rank Compression of Deep Neural Networks with Modified =
Beam-Search and Modified Stable Rank,=E2=80=9D arXiv :2111.15179 [cs], =
Nov. 2021.
[7] Wei He, Meiqing Wu, Mingfu Liang, and Siew-Kei Lam, =E2=80=9CCap : =
Context-aware pruning for semantic segmentation,=E2=80=9D in 2021 IEEE =
Winter Conference on Applications of Computer Vision (WACV), 2021, pp. =
959=E2=80=93968.
[8] Mengde Xu, Zheng Zhang, Fangyun Wei, Yutong Lin, Yue Cao, Han Hu, =
and Xiang Bai, =E2=80=9CA Simple Baseline for Zero-shot Semantic =
Segmentation with Pre-trained Vision-language Model,=E2=80=9D arXiv =
:2112.14757 [cs], Dec. 2021.
[9] Maxime Bucher, Tuan-Hung Vu, Matthieu Cord, and Patrick P=C3=A9rez, =
=E2=80=9CZero-shot semantic segmentation,=E2=80=9D in Advances in Neural =
Information Processing Systems 32 : Annual Conference on Neural =
Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, =
Vancouver, BC, Canada, Hanna M. Wallach, Hugo Larochelle, Alina =
Beygelzimer, Florence d=E2=80=99Alch=C3=A9-Buc, Emily B. Fox, and Roman =
Garnett, Eds., 2019, pp. 466=E2=80=93477.

A pdf version of the position is available at
https://lezoray.users.greyc.fr/tmp/PhD_FrugalAI.pdf =
<https://lezoray.users.greyc.fr/tmp/PhD_FrugalAI.pdf>

Olivier L=C3=89ZORAY
Full Professor of Computer Science=20

University of Caen Normandy
West Normandy Institute of Technology
Multimedia and Internet Department
F-50000 SAINT-L=C3=94+33(0)233775514 <tel:+33 2 33 77 55 14>	GREYC =
UMR CNRS 6072
Image Team - ENSICAEN
6 Bd. Marechal Juin
F-14000 CAEN+33(0)231452927 <tel:+33 2 31 45 29 27>
 <https://linkedin.com/in/olivier-lezoray-0983114/>	 =
<skype:olezoray>https://lezoray.users.greyc.fr =
<https://lezoray.users.greyc.fr/>
 <https://unicaen.fr/>

=0A
--Apple-Mail=_93ECBF97-1B91-49F4-97D0-7BC8DF9606FD
Content-Transfer-Encoding: quoted-printable
Content-Type: text/html;
	charset=utf-8

<html><head><meta http-equiv=3D"Content-Type" content=3D"text/html; =
charset=3Dutf-8"></head><body style=3D"word-wrap: break-word; =
-webkit-nbsp-mode: space; line-break: after-white-space;" class=3D""><div =
class=3D"">=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</div><div class=3D"">PhD =
position at University of Caen, CNRS GREYC Laboratory</div><div =
class=3D"">on "Frugal AI for image segmentation"</div><div =
class=3D"">=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</div><div class=3D""><br =
class=3D""></div><div class=3D"">Topic</div><div =
class=3D"">-----</div><div class=3D""><br class=3D""></div><div =
class=3D"">The advent of deep learning has been a real tsunami in the =
machine learning community, leading to results, especially in computer =
vision, that we would not have expected a few years before. For many =
vision tasks, the performances of deep learning algorithms have become =
equivalent or even superior to human performances.</div><div =
class=3D""><br class=3D""></div><div class=3D"">However, these results =
have been obtained at the cost of ever-increasing use of resources such =
as: the size of the model, the time and energy needed to train them, =
with ever-larger databases and ever-higher annotation requirements. This =
increase in resource requirements has major drawbacks, related to the =
impact that ML has on the environment, the difficulty to implement =
models on embedded architectures, or the challenges raised when models =
have to be trained on tasks for which little training data is =
available.</div><div class=3D""><br class=3D""></div><div class=3D"">These=
 observations have very recently led some authors [1, 2] to introduce =
the concept of frugal machine learning and to define what a frugal =
machine learning methodology should be, and how to evaluate =
frugality.</div><div class=3D""><br class=3D""></div><div class=3D"">In =
this dissertation, we will study frugality in the context of AI for =
image segmentation [3]. The objective will be to propose frugal models =
that can provide efficient results while being structured to provide a =
reduced time and space complexity. More precisely, we will consider =
several aspects of frugality and take inspiration from the following =
recent works : i) the conception of lightweight models by design [4, 5] =
ii) the compression of existing models [6] iii) the pruning of existing =
segmentation models [4, 7] iv) frugality on image label and zero shot =
image segmentation [8, 9].</div><div class=3D""><br class=3D""></div><div =
class=3D"">Qualifications</div><div class=3D"">--------------</div><div =
class=3D""><br class=3D""></div><div class=3D"">Candidates must have an =
MSc or engineering degree in a field related to computer science, =
electrical engineering, or applied mathematics, with strong programming =
skills (in particular with deep learning frameworks). Experience with =
image processing will be a plus. Candidates are expected to have =
abilities to write scientific reports and communicate research results =
at conferences in English.</div><div class=3D""><br class=3D""></div><div =
class=3D"">Information and application</div><div =
class=3D"">---------------------------</div><div class=3D""><br =
class=3D""></div><div class=3D"">The position is starting as soon as =
possible with a salary of 32 kEuros gross, and will be located in Caen, =
France.</div><div class=3D""><br class=3D""></div><div =
class=3D"">Applications should include the following documents in =
electronic format: i) A short motivation letter stating why you are =
interested in this project, ii) A detailed CV describing your past =
research background related to the position iii) The transcripts for =
master degrees. iv) The contact information for three references (do not =
include the reference letters with your applications as we will only ask =
for the reference letters for short-listed candidates).</div><div =
class=3D""><br class=3D""></div><div class=3D"">Please send your =
application package to&nbsp;<a href=3D"mailto:frederic.jurie@unicaen.fr" =
class=3D"">frederic.jurie@unicaen.fr</a>&nbsp;&nbsp; and&nbsp;<a =
href=3D"mailto:olivier.lezoray@unicaen.fr" =
class=3D"">olivier.lezoray@unicaen.fr</a>&nbsp;</div><div class=3D""><br =
class=3D""></div><div class=3D"">Ideally located in the heart of =
Normandy, two hours from Paris and just 10 minutes away from the =
beaches, Caen, William the Conqueror=E2=80=99s hometown, is a lively and =
dynamic city.</div><div class=3D""><br class=3D""></div><div =
class=3D""><br class=3D""></div><div class=3D"">References</div><div =
class=3D"">----------</div><div class=3D""><br class=3D""></div><div =
class=3D"">[1] Lingjiao Chen, Matei Zaharia, and James Y. Zou, =
=E2=80=9CFrugalML : How to use ML Prediction APIs more accurately and =
cheaply,=E2=80=9D in Advances in Neural Information Processing Systems =
33 : Annual Conference on Neural Information Processing Systems 2020, =
NeurIPS 2020, December 6-12, 2020, Virtual, Hugo Larochelle, =
Marc=E2=80=99Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and =
Hsuan-Tien Lin, Eds., 2020.</div><div class=3D"">[2] Mikhail Evchenko, =
Joaquin Vanschoren, Holger H. Hoos, Marc Schoenauer, and Mich=C3=A8le =
Sebag, =E2=80=9CFrugal Machine Learning,=E2=80=9D arXiv :2111.03731 [cs, =
eess], Nov. 2021.</div><div class=3D"">[3] Shervin Minaee, Yuri Y. =
Boykov, Fatih Porikli, Antonio J Plaza, Nasser Kehtarnavaz, and Demetri =
Terzopoulos, =E2=80=9CImage segmentation using deep learning : A =
survey,=E2=80=9D IEEE Transactions on Pattern Analysis and Machine =
Intelligence, pp. 1=E2=80=931, 2021.</div><div class=3D"">[4] Linjie =
Wang, Quan Zhou, Chenfeng Jiang, Xiaofu Wu, and Longin &nbsp;Jan =
Latecki, =E2=80=9CDRBANET: A Lightweight Dual-Resolution Network for =
Semantic Segmentation with Boundary Auxiliary,=E2=80=9D arXiv =
:2111.00509 [cs], Oct. 2021.</div><div class=3D"">[5] Enze Xie, Wenhai =
Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, and Ping Luo, =
=E2=80=9CSegformer : Simple and efficient design for semantic =
segmentation with transformers,=E2=80=9D CoRR, vol. abs/2105.15203, =
2021.</div><div class=3D"">[6] Moonjung Eo, Suhyun Kang, and Wonjong =
Rhee, =E2=80=9CA Highly Effective Low-Rank Compression of Deep Neural =
Networks with Modified Beam-Search and Modified Stable Rank,=E2=80=9D =
arXiv :2111.15179 [cs], Nov. 2021.</div><div class=3D"">[7] Wei He, =
Meiqing Wu, Mingfu Liang, and Siew-Kei Lam, =E2=80=9CCap : Context-aware =
pruning for semantic segmentation,=E2=80=9D in 2021 IEEE Winter =
Conference on Applications of Computer Vision (WACV), 2021, pp. =
959=E2=80=93968.</div><div class=3D"">[8] Mengde Xu, Zheng Zhang, =
Fangyun Wei, Yutong Lin, Yue Cao, Han Hu, and Xiang Bai, =E2=80=9CA =
Simple Baseline for Zero-shot Semantic Segmentation with Pre-trained =
Vision-language Model,=E2=80=9D arXiv :2112.14757 [cs], Dec. =
2021.</div><div class=3D"">[9] Maxime Bucher, Tuan-Hung Vu, Matthieu =
Cord, and Patrick P=C3=A9rez, =E2=80=9CZero-shot semantic =
segmentation,=E2=80=9D in Advances in Neural Information Processing =
Systems 32 : Annual Conference on Neural Information Processing Systems =
2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, Hanna M. =
Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d=E2=80=99Alch=C3=A9=
-Buc, Emily B. Fox, and Roman Garnett, Eds., 2019, pp. =
466=E2=80=93477.</div><div class=3D""><br class=3D""></div><div =
class=3D"">A pdf version of the position is available at</div><div =
class=3D""><a href=3D"https://lezoray.users.greyc.fr/tmp/PhD_FrugalAI.pdf"=
 =
class=3D"">https://lezoray.users.greyc.fr/tmp/PhD_FrugalAI.pdf</a></div><d=
iv class=3D""><br class=3D""></div><div class=3D"">
<hr class=3D"">
<table width=3D"500" cellspacing=3D"0" cellpadding=3D"0" class=3D"">=20
	<tbody class=3D""><tr class=3D""> <td style=3D"vertical-align: =
top; text-align:left;color:#000000;font-size:12px;font-family:helvetica, =
arial;; text-align:left" class=3D"">=20
		<span class=3D""><b class=3D""><span =
style=3D"color:#000000;font-size:15px;font-family:helvetica, arial" =
class=3D"">Olivier L=C3=89ZORAY</span></b><br class=3D""> Full Professor =
of Computer Science</span> <br class=3D""><br class=3D"">=20

		<span =
style=3D"color:#000000;font-size:15px;font-family:helvetica, arial" =
class=3D""><b class=3D"">University of Caen Normandy</b>
		<table class=3D"">
		<tbody class=3D""><tr =
style=3D"font-size:8pt;font-family:helvetica, arial" class=3D"">
			<td class=3D"">West Normandy Institute of =
Technology<br class=3D"">Multimedia and Internet Department<br =
class=3D"">F-50000 SAINT-L=C3=94
			<a href=3D"tel:+33 2 33 77 55 14" =
style=3D"color:#3388cc;text-decoration:none" =
class=3D"">+33(0)233775514</a>
			</td>
			<td class=3D"">
				GREYC UMR CNRS 6072<br class=3D"">Image =
Team - ENSICAEN<br class=3D"">6 Bd. Marechal Juin<br class=3D"">F-14000 =
CAEN
				<a href=3D"tel:+33 2 31 45 29 27" =
style=3D"color:#3388cc;text-decoration:none" =
class=3D"">+33(0)231452927</a>
			</td>
		</tr>
		</tbody></table>
		</span>

		<table cellpadding=3D"0" border=3D"0" class=3D""><tbody =
class=3D""><tr class=3D""><td style=3D"padding-right:4px" class=3D""><a =
href=3D"https://linkedin.com/in/olivier-lezoray-0983114/" =
style=3D"display: inline-block" class=3D""><img width=3D"30" height=3D"30"=
 src=3D"https://s1g.s3.amazonaws.com/7583fe34c2ad59e0367b6f4773f07bf3.png"=
 alt=3D"LinkedIn" style=3D"border:none" class=3D""></a></td><td =
style=3D"padding-right:4px" class=3D""><a href=3D"skype:olezoray" =
style=3D"display: inline-block" class=3D""><img width=3D"30" height=3D"30"=
 src=3D"https://s1g.s3.amazonaws.com/7b0d8c63303d92a487c23d47895fec48.png"=
 alt=3D"Skype" style=3D"border:none" =
class=3D""></a></td></tr></tbody></table><a =
href=3D"https://lezoray.users.greyc.fr" =
style=3D"text-decoration:none;color:#3388cc" =
class=3D"">https://lezoray.users.greyc.fr</a><br class=3D""> </td> <td =
style=3D"border-right:solid #000000 2px" width=3D"12" class=3D""></td>=20=


		<td width=3D"138" =
style=3D"vertical-align:top;padding-left:10px" class=3D""><a =
style=3D"display:inline-block" href=3D"https://unicaen.fr" class=3D""><img=
 style=3D"border:none" width=3D"138" =
src=3D"https://s1g.s3.amazonaws.com/a85db239c732c19b92021c4f24668e70.png" =
class=3D""></a></td>=20

	</tr>=20
</tbody></table>=20
</div>
<br class=3D"">
<br>=
=0A<br>=
</body></html>=

--Apple-Mail=_93ECBF97-1B91-49F4-97D0-7BC8DF9606FD--
