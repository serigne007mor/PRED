Return-Path: <p_bruneau@hotmail.com>
X-Original-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa62.u12.univ-nantes.prive
Received: from BounceSmtp1.univ-nantes.fr (bouncesmtp1.u12.univ-nantes.prive [172.20.12.66])
	by sympa62.u12.univ-nantes.prive (Postfix) with ESMTP id 2878C14006F3
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Thu, 27 Jul 2023 10:08:51 +0200 (CEST)
Received: from mx3.univ-nantes.fr (MX3.univ-nantes.fr [193.52.101.137])
	by BounceSmtp1.univ-nantes.fr (Postfix) with ESMTP id 1F6713F03
	for <polytech_liste-egc@sympa62.u12.univ-nantes.prive>; Thu, 27 Jul 2023 10:08:51 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mx3.univ-nantes.fr (Postfix) with ESMTP id 1548C20019
	for <liste-egc@polytech.univ-nantes.fr>; Thu, 27 Jul 2023 10:08:51 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
X-Spam-Flag: NO
X-Spam-Score: 0.012
X-Spam-Level:
X-Spam-Status: No, score=0.012 tagged_above=-1000 required=5
	tests=[CRM114_UNSURE=0.1, DKIM_SIGNED=0.1, DKIM_VALID=-0.1,
	DKIM_VALID_AU=-0.1, DKIM_VALID_EF=-0.1, FREEMAIL_FROM=0.001,
	HTML_MESSAGE=0.001, RCVD_IN_DNSWL_NONE=-0.0001, RCVD_IN_WSFF=0.01,
	SPF_HELO_NONE=0.001, SPF_PASS=-0.001, UN_PHISHING_PW=0.1]
	autolearn=disabled
X-CRM114-Status: UNSURE ( 1.4879 )
X-CRM114-CacheID: 
Authentication-Results: univ-nantes.fr (amavisd-new); dkim=pass (2048-bit key)
	header.d=gmail.com
Received: from mx3.univ-nantes.fr ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id 77cFGEOVgZaf for <liste-egc@polytech.univ-nantes.fr>;
	Thu, 27 Jul 2023 10:08:48 +0200 (CEST)
Received-SPF: Pass (mailfrom) identity=mailfrom; client-ip=2a00:1450:4864:20::52d; helo=mail-ed1-x52d.google.com; envelope-from=hakim.hacid@gmail.com; receiver=liste-egc@polytech.univ-nantes.fr 
Authentication-Results: dmarc.univ-nantes.fr; dmarc=pass (p=none dis=none) header.from=gmail.com
Authentication-Results: dmarc.univ-nantes.fr; spf=pass smtp.mailfrom=gmail.com
Authentication-Results: dkim.univ-nantes.fr;
	dkim=pass (2048-bit key; unprotected) header.d=gmail.com header.i=@gmail.com header.a=rsa-sha256 header.s=20221208 header.b=RYL9eswC;
	dkim-atps=neutral
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from mail-ed1-x52d.google.com (mail-ed1-x52d.google.com [IPv6:2a00:1450:4864:20::52d])
	by mx3.univ-nantes.fr (Postfix) with ESMTPS id D7B2C20606
	for <liste-egc@polytech.univ-nantes.fr>; Thu, 27 Jul 2023 10:08:48 +0200 (CEST)
Received: by mail-ed1-x52d.google.com with SMTP id 4fb4d7f45d1cf-51a52a7d859so4064958a12.0
        for <liste-egc@polytech.univ-nantes.fr>; Thu, 27 Jul 2023 01:08:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20221208; t=1690445328; x=1691050128;
        h=to:subject:message-id:date:from:mime-version:from:to:cc:subject
         :date:message-id:reply-to;
        bh=rCPQLtPRbyyxjJwnyxdeCTs64/VFJLfIP4GoNotewtw=;
        b=RYL9eswCCFCSlm/fL0VkeMFgFCnAoNV5OnREcvPziAX0LXe3Cgl0GDmTfuv+atsEXY
         4LLpKeyu9mtMq6JU3FBGUyj3/qZpD4BvHLjEASTaFfrdxsizhxEAqq/WPc3BabX1rL52
         Fp0KxjDWTHfNzG9cNRkg7jJhWvJNZKDtWlDpiTedG2hDGtiji92yhgwiRDd5DpYNDmoC
         CcOdVD9kyysgcoi8ocZIMo8enCjDWgdrAL1chd7qeAWSBzBX8/fwOFn+4dfyxNg53+yj
         BiDPxwqbujMCsbx1Azfoh3xmvQqZpP6moZHVOEb5y0N3Ib3wg55jTaPG92VYSS5viA/t
         /d1Q==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20221208; t=1690445328; x=1691050128;
        h=to:subject:message-id:date:from:mime-version:x-gm-message-state
         :from:to:cc:subject:date:message-id:reply-to;
        bh=rCPQLtPRbyyxjJwnyxdeCTs64/VFJLfIP4GoNotewtw=;
        b=GzlzumU/BQJ7ecZOn52Ft4K/w+kY4ApYP/NfbI21KEy/ZAVpZvzcrD07G9jXoF8Zlz
         rpNu0gHmWHUJCqQYLvy90Eat9wV0sEY+J2q7LC3jWwf+pWbT0FvK4YTtf6AahZJC8DXp
         Gbvz74BYEHzixrmI++T5dx1SBtqFc5jL/32vVK+WX9A0O1q417RMhZOm1BDj9MbyF1B/
         UqNMKHqaRUJWu9fB7SOT6hoq326Th0q9CqVsupLyRLDCL6pH8V7UT3qnNyaMlknN+UG1
         kztbXwyeylE7wYNt5dfePlTjBDTwStAvSaOlNqq9mdnvBTtfmWA9+uMYKSCaM1g5+0aY
         6xcg==
X-Gm-Message-State: ABy/qLZqHDsl2CDu/8UgYz8v4BWtiNc41XP35rUMzPd3zkNMlchwywo/
	PeZGlQxaeu5KLiZhSJVYzrznSn2MlHgsPBkNR38QKHzsrtQ=
X-Google-Smtp-Source: APBJJlGF6af5Go5bi3FTNbSeDZb5yyutyXdCJAnAf2Qa+yIH25iOtP+VogqBchF+wta9s8c+qSiTnNNp5dAGtQ0YWsU=
X-Received: by 2002:a05:6402:14ce:b0:51f:f079:875f with SMTP id
 f14-20020a05640214ce00b0051ff079875fmr1815678edx.4.1690445327678; Thu, 27 Jul
 2023 01:08:47 -0700 (PDT)
MIME-Version: 1.0
From: Hakim Hacid <hakim.hacid@gmail.com>
Date: Thu, 27 Jul 2023 12:08:36 +0400
Message-ID: <CAF72FM9gQDFEXDHoS=6BtPu3f59Hr4zcJkSiNd0vq9rUm7ZrWQ@mail.gmail.com>
To: liste-egc@polytech.univ-nantes.fr
Content-Type: multipart/alternative; boundary="00000000000044c2f4060173798e"
X-Validation-by: p_bruneau@hotmail.com
Subject: [liste-egc] SPICE@ICDM 2023: Call for papers

--00000000000044c2f4060173798e
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
THE FIRST INTERNATIONAL WORKSHOP ON
SMALL PRECISION FOR MACHINE LEARNING (SPICE 2023)
In Conjunction with ICDM 2023

1-4, December 2023, Shanghai, China
http://spice2023.josueonline.com/
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D

CALL FOR PAPERS:
----------------
The surge in demand and interest in more potent AI and machine learning
applications has fueled the race to build larger models, powerful
algorithms and heavy digital infrastructures to ensure production and
delivery breakthroughs in machine learning (ML) systems. At the heart of
this technological transformation, it is hard to omit the role of dedicated
processors for ML applications to accelerate the learning process and speed
up computation of machine learning models for both training and inference
workloads, and to cope with trends of the increasing complexity of ML
applications.

As model and dataset size requirements of deep learning applications
continue to increase, in order to address the growing compute, storage, and
connectivity requirements,  scalability of machine learning systems becomes
even more critical. Indeed, efficient training of large models, is
synonymous with the efficient use of the available compute, power, memory,
and networking resources to overcome any physical limitations when training
such large models over a large distributed infrastructure.

Choice of computer arithmetic is an important part in any accelerator
design, as it has a direct impact on the hardware complexity and compute
efficiency, as well as the utilization of the available memory and
communication bandwidth. In addition, efficient numerical representation is
indispensable at it offers prospects of an improved power efficiency
achieved through higher compute throughput and better utilization of the
communication bandwidth.
In addition to model training and tuning, several challenges arise during
deployment of large models because of the increased computational
complexity and tight latency requirements. To overcome these challenges,
numerical quantization for inference is a necessity to utilize the limited
compute and memory available in small-powered devices or infrastructure
used to serve these workloads.

With the slowdown of Moore's law, and the reality that the current silicon
technology is no longer able to double the processing speed with every new
silicon generation at a constant power, the need for today=E2=80=99s and to=
morrow's
ML processors and accelerators to make more efficient use of the available
power is paramount. The demand is expected to grow and catch more interest
due to the current physical limitations of cloud, edge, and mobile
solutions. This workshop intends to gather researchers and practitioners in
the area of low precision arithmetic for machine learning and offer a
platform for an exchange of ideas, and to discuss the progress in the area
as well as to address emerging future challenges. Areas of interest
include, but are not limited to:

=E2=80=A2 Low precision training
=E2=80=A2 Low precision inference
=E2=80=A2 Sparsity
=E2=80=A2 On-chip ring communication
=E2=80=A2 Power management
=E2=80=A2 Benchmarks and frameworks for low precision ML
=E2=80=A2 NLP optimizations
=E2=80=A2 Computer vision optimizations
=E2=80=A2 Applications of low precision ML
=E2=80=A2 Strategies for low precision ML
=E2=80=A2 Standardization

SPECIAL ISSUE
--------------
The workshop organizers are exploring special issue opportunities with few
journals. More information will be available very soon.

IMPORTANT DATES
-----------------
=E2=80=A2 September 3, 2023: papers submission
=E2=80=A2 September 24, 2023: Notification of workshop papers acceptance to=
 authors
=E2=80=A2 October 1, 2023: Camera-ready deadline
=E2=80=A2 December 4, 2023: Workshops date

WORKSHOP ORGANIZERS:
---------------------
- Badreddine Noune, Technology Innovation Institute Abu Dhabi, UAE
- Hakim Hacid, Technology Innovation Institute, Abu Dhabi, UAE
- Imran Junejo, AMD, Canada

SUBMISSION WEBSITE:
--------------------
Coming soon!

--00000000000044c2f4060173798e
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br>THE FIRST INTE=
RNATIONAL WORKSHOP ON <br>SMALL PRECISION FOR MACHINE LEARNING (SPICE 2023)=
<br>In Conjunction with ICDM 2023<br><br>1-4, December 2023, Shanghai, Chin=
a<br><a href=3D"http://spice2023.josueonline.com/">http://spice2023.josueon=
line.com/</a>=C2=A0<br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br><br>CALL=
 FOR PAPERS:<br>----------------<br>The surge in demand and interest in mor=
e potent AI and machine learning applications has fueled the race to build =
larger models, powerful algorithms and heavy digital infrastructures to ens=
ure production and delivery breakthroughs in machine learning (ML) systems.=
 At the heart of this technological transformation, it is hard to omit the =
role of dedicated processors for ML applications to accelerate the learning=
 process and speed up computation of machine learning models for both train=
ing and inference workloads, and to cope with trends of the increasing comp=
lexity of ML applications.<br><br>As model and dataset size requirements of=
 deep learning applications continue to increase, in order to address the g=
rowing compute, storage, and connectivity requirements, =C2=A0scalability o=
f machine learning systems becomes even more critical. Indeed, efficient tr=
aining of large models, is synonymous with the efficient use of the availab=
le compute, power, memory, and networking resources to overcome any physica=
l limitations when training such large models over a large distributed infr=
astructure.<br><br>Choice of computer arithmetic is an important part in an=
y accelerator design, as it has a direct impact on the hardware complexity =
and compute efficiency, as well as the utilization of the available memory =
and communication bandwidth. In addition, efficient numerical representatio=
n is indispensable at it offers prospects of an improved power efficiency a=
chieved through higher compute throughput and better utilization of the com=
munication bandwidth.<br>In addition to model training and tuning, several =
challenges arise during deployment of large models because of the increased=
 computational complexity and tight latency requirements. To overcome these=
 challenges, numerical quantization for inference is a necessity to utilize=
 the limited compute and memory available in small-powered devices or infra=
structure used to serve these workloads.<br><br>With the slowdown of Moore&=
#39;s law, and the reality that the current silicon technology is no longer=
 able to double the processing speed with every new silicon generation at a=
 constant power, the need for today=E2=80=99s and tomorrow&#39;s ML process=
ors and accelerators to make more efficient use of the available power is p=
aramount. The demand is expected to grow and catch more interest due to the=
 current physical limitations of cloud, edge, and mobile solutions. This wo=
rkshop intends to gather researchers and practitioners in the area of low p=
recision arithmetic for machine learning and offer a platform for an exchan=
ge of ideas, and to discuss the progress in the area as well as to address =
emerging future challenges. Areas of interest include, but are not limited =
to:<br><br>	=E2=80=A2 Low precision training<br>	=E2=80=A2 Low precision in=
ference<br>	=E2=80=A2 Sparsity<br>	=E2=80=A2 On-chip ring communication<br>=
	=E2=80=A2 Power management<br>	=E2=80=A2 Benchmarks and frameworks for low=
 precision ML<br>	=E2=80=A2 NLP optimizations<br>	=E2=80=A2 Computer vision=
 optimizations<br>	=E2=80=A2 Applications of low precision ML<br>	=E2=80=A2=
 Strategies for low precision ML<br>	=E2=80=A2 Standardization<br><br>SPECI=
AL ISSUE<br>--------------<br>The workshop organizers are exploring special=
 issue opportunities with few journals. More information will be available =
very soon. <br><br>IMPORTANT DATES<br>-----------------<br>	=E2=80=A2 Septe=
mber 3, 2023: papers submission<br>	=E2=80=A2 September 24, 2023: Notificat=
ion of workshop papers acceptance to authors<br>	=E2=80=A2 October 1, 2023:=
 Camera-ready deadline<br>	=E2=80=A2 December 4, 2023: Workshops date<br><b=
r>WORKSHOP ORGANIZERS: <br>---------------------<br>- Badreddine Noune, Tec=
hnology Innovation Institute Abu Dhabi, UAE<br>- Hakim Hacid, Technology In=
novation Institute, Abu Dhabi, UAE<br>- Imran Junejo, AMD, Canada<br><br>SU=
BMISSION WEBSITE:<br>--------------------<br>Coming soon! <br><br></div>

--00000000000044c2f4060173798e--
