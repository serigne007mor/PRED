Return-Path: <nistor_grozavu@yahoo.com>
X-Original-To: polytech_liste-egc@sympa6.univ-nantes.prive
Delivered-To: polytech_liste-egc@sympa6.univ-nantes.prive
Received: from BounceSmtp1.univ-nantes.fr (BounceSMTP1.univ-nantes.prive [172.20.12.66])
	by sympa6.univ-nantes.prive (Postfix) with ESMTP id D6DBE20BC19
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Tue, 26 Apr 2011 15:22:20 +0200 (CEST)
Received: from mx3.univ-nantes.fr (MX3.univ-nantes.fr [193.52.101.137])
	by BounceSmtp1.univ-nantes.fr (Postfix) with ESMTP id D369840B23E
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Tue, 26 Apr 2011 15:22:20 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by mx3.univ-nantes.fr (Postfix) with ESMTP id C4A2F100FFA4
	for <polytech_liste-egc@sympa6.univ-nantes.prive>; Tue, 26 Apr 2011 15:22:20 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at univ-nantes.fr
Received: from mx3.univ-nantes.fr ([127.0.0.1])
	by localhost (univ-nantes.fr [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id w8vSZiGqX9Yz
	for <polytech_liste-egc@sympa6.univ-nantes.prive>;
	Tue, 26 Apr 2011 15:22:19 +0200 (CEST)
X-Greylist: domain auto-whitelisted by SQLgrey-1.6.7
Received: from web24008.mail.ird.yahoo.com (web24008.mail.ird.yahoo.com [87.248.114.95])
	by mx3.univ-nantes.fr (Postfix) with SMTP id 04CF68C7
	for <liste-egc@polytech.univ-nantes.fr>; Tue, 26 Apr 2011 15:22:18 +0200 (CEST)
Received: (qmail 36475 invoked by uid 60001); 26 Apr 2011 13:22:18 -0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s1024; t=1303824138; bh=8CVdePre18Xh+WkQybH/8wwummq3g5l9A8UwUQUYvQI=; h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:MIME-Version:Content-Type; b=OCGbqLNqKxFU/OjigZKYOsO8UcB1GkZ1igxP5k/wrvsY8RDv2DO/oO0QGcwbhTP1JMN3HLo1nXc/9qeDC8hXfWUFB9NTERb9+Re0GsKChhOyVmjGWR2YpTG4UeJSY8D0NG0Fx0lv7M8aSZ3W+ZwdJcq4lBBJMYm0oMGoRUJR6bM=
DomainKey-Signature:a=rsa-sha1; q=dns; c=nofws;
  s=s1024; d=yahoo.com;
  h=Message-ID:X-YMail-OSG:Received:X-Mailer:Date:From:Subject:To:Cc:MIME-Version:Content-Type;
  b=ygVS0oRQYEk39l8vwCxuCQLfdQCZ/RnYGzcyvH5Z1/+qm3ylX+v49o0w9pebBPRVaephvgb+jRk98J38adY740Lgsio6m+PDsATxqYNQHwkBeq+bHT4qxGe/N47YlngDM9BLu2yjaJKdLGP2SPEUzaUvYIgdmXDM66PfWhDBpR4=;
Message-ID: <572938.35753.qm@web24008.mail.ird.yahoo.com>
X-YMail-OSG: 57RIUzwVM1kS2hjy5gWDkC5CYAqJifuQFV11hRQxxzqJgvg
 _NVkcreBg1BVZkCSXsIhF4x0W33hxLcK40.b8qx8KvVJbWalz2lQW9PxNrEt
 mJglSNyMMnStxxsMQf7Y5WdSET7EOXV7NNpvxfL6sZwal.v1zh2bTAjBdQR1
 N.51IZ9uWoXYdy5xcFlazG3j2RtGDObn2hoDA5ABeBTpFEqOZrUsFkW9OYMc
 raeSDZ.JvIb8_yKzGy6tKO9_4y8n8w.UoVUvS.iuMBphwafqknDyip4HjLlZ
 13.oK1HgsDQQ9sGwgMuhocyzJAHZq8FMNCJc0ziiIrLNE7MQTiVB1aPXZXgO
 t1s69DbNMSUw17QIQSVwU7.YgDt_tDA--
Received: from [194.254.163.24] by web24008.mail.ird.yahoo.com via HTTP; Tue, 26 Apr 2011 14:22:18 BST
X-Mailer: YahooMailRC/559 YahooMailWebService/0.8.110.299900
Date: Tue, 26 Apr 2011 14:22:18 +0100 (BST)
From: Nistor Grozavu <nistor_grozavu@yahoo.com>
To: liste-egc@polytech.univ-nantes.fr
Cc: nistor grozavu <Nistor.Grozavu@lipn.univ-paris13.fr>
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="0-843355737-1303824138=:35753"
X-Validation-by: fabrice.guillet@univ-nantes.fr
Subject: [liste-egc] ICONIP 2011 Special Session on Combining Multiple
 Learners : call for papers


--0-843355737-1303824138=:35753
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

Dear Colleagues,

2011 International Conference on Neural Information Processing (ICONIP 2011=
)=20
will be held in Shanghai, China. It is an annual event, organized since 199=
4 by=20
the Asia Pacific Neural Network Assembly (APNNA).

CALL FOR PAPERS :=20
Special Session on Combining Multiple Learners :
http://iconip2011.sjtu.edu.cn/S7.html


Organizers:
Youn=E8s Bennani, Full Professor, Paris 13 University.=20
Nistor Grozavu, Associate Professor, Paris 13 University.=20
Mohamed Nadif, Full Professor, Paris 5 University.=20
Nicoleta Rogovschi, Associate Professor, Paris 5 University.=20

Contact:
Nistor Grozavu
Email: Nistor.Grozavu@lipn.univ-paris13.fr=20

Description:
This special session will cover original and pioneering contributions, theo=
ry as=20
well as applications on creating and combining learning models, and aim at =
an=20
inspiring discussion on the recent progress and the future development. Lea=
rners=20
based on different paradigms can be combined for improved accuracy. Each=20
learning method assumes a certain model that comes with a set of assumption=
s=20
which may lead to error if the assumptions do not hold. Learning is an ill-=
posed=20
problem and with finite data each algorithm converges to a different soluti=
on=20
and fails under variant circumstances. In learning models combination, it i=
s=20
possible to make a distinction between two main modes: ensemble and modular=
. For=20
an ensemble approach, several solutions to the same task, or task component=
, are=20
combined to yield a more reliable estimate. In the modular approach case,=20
particular aspects of a task are deal with by specialist components before =
being=20
recombined to form a global solution. In this special session, the reasons =
for=20
combining learning models and the main methods for creating and combining w=
ill=20
be presented. Also, the effectiveness of these methods will be discussed=20
considering the concepts of diversity and selection of these approaches. To=
pics=20
of interest include but not limited to:=20


	* Modular approaches
	* Hybrides systems
	* Collaboratif learning
	* Mixtures of distributions
	* Mixtures of experts
	* Ensemble methods
	* Bagging approaches
	* Boosting techniques
	* Task decomposition
Yours sincerely,
Nistor Grozavu
 Best regards,
Nistor Grozavu
PhD, Computer Science Laboratory of the Paris 13 University (LIPN)
http://www-lipn.univ-paris13.fr/~grozavu/
tel: +33 (0)626901790

--0-843355737-1303824138=:35753
Content-Type: text/html; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

<html><head><style type=3D"text/css"><!-- DIV {margin:0px;} --></style></he=
ad><body><div style=3D"font-family:bookman old style,new york,times,serif;f=
ont-size:14pt"><p>Dear Colleagues,<br>
</p>
<p>2011 International Conference on Neural Information Processing
(ICONIP 2011) will be held in Shanghai, China. It is an annual event,
organized since 1994 by the Asia Pacific Neural Network Assembly
(APNNA).</p>
<p><br></p><p>CALL FOR PAPERS : <br>
Special Session on Combining Multiple Learners :<br>
<a class=3D"moz-txt-link-freetext" href=3D"http://iconip2011.sjtu.edu.cn/S7=
.html">http://iconip2011.sjtu.edu.cn/S7.html</a><br>
<br>
</p>
<p><span class=3D"subHeader">Organizers:</span><br>
<a href=3D"http://www-lipn.univ-paris13.fr/%7Ebennani/" target=3D"_blank" c=
lass=3D"style1">Youn=E8s Bennani, Full Professor</a>, Paris 13
University. <br>
<a href=3D"http://www-lipn.univ-paris13.fr/%7Egrozavu/" target=3D"_blank" c=
lass=3D"style1">Nistor Grozavu, Associate Professor</a>, Paris 13
University. <br>
<a href=3D"http://www.math-info.univ-paris5.fr/%7Enadifmoh/" target=3D"_bla=
nk" class=3D"style1">Mohamed Nadif, Full Professor</a>,
Paris 5 University. <br>
<a href=3D"http://www-lipn.univ-paris13.fr/%7Erogovschi/" target=3D"_blank"=
 class=3D"style1">Nicoleta Rogovschi, Associate Professor</a>, Paris 5
University. <br>
<br>
<span class=3D"subHeader">Contact:</span><br>
<a href=3D"http://www-lipn.univ-paris13.fr/%7Ebennani/" target=3D"_blank" c=
lass=3D"style1">Nistor Grozavu</a><br>
Email: <a href=3D"mailto:Nistor.Grozavu@lipn.univ-paris13.fr" target=3D"_bl=
ank" class=3D"style1">Nistor.Grozavu@lipn.univ-paris13.fr</a>
<br>
<br>
<span class=3D"subHeader">Description:</span><br>
This special session will cover original and pioneering
contributions,
theory as well as applications on creating and combining learning
models, and aim at an inspiring discussion on the recent progress and
the future development. Learners based on different paradigms can be
combined for improved accuracy. Each learning method assumes a certain
model that comes with a set of assumptions which may lead to error if
the assumptions do not hold. Learning is an ill-posed problem and with
finite data each algorithm converges to a different solution and fails
under variant circumstances. In learning models combination, it is
possible to make a distinction between two main modes: ensemble and
modular. For an ensemble approach, several solutions to the same task,
or task component, are combined to yield a more reliable estimate. In
the modular approach case, particular aspects of a task are deal with
by specialist components before being recombined to form a global
solution. In this special session, the reasons for combining learning
models and the main methods for creating and combining will be
presented. Also, the effectiveness of these methods will be discussed
considering the concepts of diversity and selection of these
approaches. </p>
<span class=3D"subHeader">Topics of interest include but not limited to: </=
span><br>
<ul><li>Modular approaches</li><li>Hybrides systems</li><li>Collaboratif le=
arning</li><li>Mixtures of distributions</li><li>Mixtures of experts</li><l=
i>Ensemble methods</li><li>Bagging approaches</li><li>Boosting techniques</=
li><li>Task decomposition</li></ul>
<br>
Yours sincerely,<br>
Nistor Grozavu<div>&nbsp;</div>Best regards,<br>Nistor Grozavu<br>PhD, Comp=
uter Science Laboratory of the Paris 13 University (LIPN)<br><span><a targe=
t=3D"_blank" href=3D"http://www-lipn.univ-paris13.fr/%7Egrozavu/">http://ww=
w-lipn.univ-paris13.fr/~grozavu/</a></span><br>tel: +33 (0)626901790<div><b=
r></div>
</div></body></html>=

--0-843355737-1303824138=:35753--
